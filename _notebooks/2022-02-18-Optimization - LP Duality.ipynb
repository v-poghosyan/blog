{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1b098e2",
   "metadata": {},
   "source": [
    "# Optimization -  LP Duality\n",
    "\n",
    "> LP Weak and Strong Duality, Complementary Slackness, Farkas' Lemma, Separation Arguments and Theorems of the Alternative\n",
    "\n",
    "- hide: false\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: false\n",
    "- categories: ['Optimization','Applied Mathematics','Proofs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a962e169",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Every linear program (a primal) has a closely related linear program called its dual which can be thought of as its evil twin. If the primal LP is a minimization problem in $n$ variables and $m$ constraints, then its dual is a maximization problem in $m$ variables and $n$ constraints. In this post, we will closely examine the nature of the relationship between the primal and the dual. \n",
    "\n",
    "We will see that the key relationship between the primal and the dual is the fact that the dual's optimal value agrees with that of the primal. So, solving the dual guarantees that we've also solved the primal. Furthermore, as we shall see, taking the dual of the dual gives back the primal, so this relationship is a two way street. That is, if we've solved the primal then we've also solved the dual. \n",
    "\n",
    "This is what makes Duality Theory so useful in practice. To have a related, possibly easier, problem for a given optimization problem for free is a huge benefit. Even if the dual does not turn out to be easier to solve, it still has the potential to shed some light on the structure of the primal problem due to the various theoretical ties between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81a0e54",
   "metadata": {},
   "source": [
    "# Weak Duality\n",
    "\n",
    "To show that a feasible and bounded primal and its feasible and bounded dual agree on the optimal value, we start small by first showing that one's optimal value is upper bounded by that of the other. We do that by proving the theorem of *weak duality*.\n",
    "\n",
    "Henceforth, without loss of generality, we will assume the primal is a minimization problem and, consequently, the dual is a maximization problem. \n",
    "\n",
    "That is, the primal is an LP of the form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b46c43",
   "metadata": {},
   "source": [
    "$\n",
    "\\begin{cases}\n",
    "\\min_x: c^Tx\n",
    "\\\\\n",
    "s.t.: \\begin{aligned} &Ax \\geq b\n",
    "\\\\ \n",
    "&x \\geq 0\n",
    "\\end{aligned}\n",
    "\\end{cases}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36781337",
   "metadata": {},
   "source": [
    "which means the dual is of the form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a66bf7",
   "metadata": {},
   "source": [
    "$\n",
    "\\begin{cases}\n",
    "\\max_p: b^Tp\n",
    "\\\\\n",
    "s.t.: \\begin{aligned} &A^Tp \\leq c\n",
    "\\\\ \n",
    "&p \\geq 0\n",
    "\\end{aligned}\n",
    "\\end{cases}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78e874d",
   "metadata": {},
   "source": [
    "> **Weak Duality:** &nbsp; For any primal feasible $x$ and for all dual feasible $p$, $c^Tx \\geq b^Tp$.\n",
    "<br>\n",
    "\n",
    "That is, any dual feasible solution $b^Tp$ is a *lower bound* for all primal feasible solutions $c^Tx$. Conversely, any primal feasible solution $c^Tx$ is an *upper bound* for all dual feasible solutions $b^Tp$. \n",
    "\n",
    "##  Proof of Weak Duality\n",
    "\n",
    "Let $(p, x)$ be respectively dual-primal feasible. Then $c^Tx = x^Tc \\geq x^TA^Tp \\geq b^Tp$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3e0e10",
   "metadata": {},
   "source": [
    "##  Max-Min Theorem\n",
    "\n",
    "In the case of primal-dual optimal points $(x^*, p^*)$, weak duality states $c^Tx^* \\geq b^Tp^*$. This is simply a restatement of the [max-min inequality](https://en.wikipedia.org/wiki/Max%E2%80%93min_inequality) within the context of LP's. \n",
    "\n",
    "As we may recall, the min-max inequality makes no assumptions about the function. It's simply true for all functions of the form $f: X \\times Y \\rightarrow \\mathbb{R}$, and it states that\n",
    "\n",
    "$$\n",
    "\\inf_{y\\in Y} \\left\\{ \\sup_{x\\in X} f(x,y) \\right\\} \\geq \\sup_{x\\in X} \\left\\{ \\inf_{y\\in Y} f(x,y) \\right\\}\n",
    "$$\n",
    "\n",
    "Since no assumption on $f$ is made, the max-min inequality certainly also applies to the special case of linear objective functions of LP's. And since we're in the special case where the optima are assumed to exist, the functions attain their optima. That is, we can replace $\\sup$ and $\\inf$ in the max-min inequality with $\\max$ and $\\min$.\n",
    "\n",
    "## Proof of Max-Min Theorem\n",
    "\n",
    "For any $f$, and $x \\in X$, $y \\in Y$ we have:\n",
    "$$f(x,y) \\geq \\min_x f(x,y)$$\n",
    "The right hand side is now only a function of $y$, so maximizing both sides w.r.t. $y$ yields: \n",
    "$$ \\max_y f(x,y) \\geq \\max_y \\left\\{ \\min_x f(x,y) \\right\\}$$\n",
    "The right hand side is now a constant, so minimizing both sides w.r.t. $x$ results in the desired conclusion.\n",
    "$$\\min_x \\left\\{ \\max_y f(x,y) \\right\\} \\geq \\max_y \\left\\{ \\min f(x,y) \\right\\}$$\n",
    "\n",
    "## Game-Theoretic Intuition of Max-Min Theorem\n",
    "\n",
    "An intuitive way to see the validity of the max-min theorem comes from [game theory](https://en.wikipedia.org/wiki/Game_theory).\n",
    "\n",
    "Suppose two players $A$, and $B$, are playing a game in which player $A$'s goal is to minimize the score $s$ whereas player $B$'s goal is to maximize it. Suppose, per the rules of the game, player $A$ has the first turn. Then player $B$'s choice is final and it restricts the actions player $A$ can take. So player $B$ has an advantage in this game. \n",
    "\n",
    "However, if a second game is played such that player $B$ must go first, then the advantage lies with player $A$. \n",
    "\n",
    "\n",
    "Formally, suppose the game is described by $f(x,y)$ where $x \\in X$ and $y \\in Y$ represent player $A$'s and player $B$'s choices respectively. \n",
    "\n",
    "In the first game player $A$ is restricted to choosing $x$ that will minimize $s_1(x) = \\max_y f(x,y)$. Consequently, the payoff in the first game will be $ s_1 = \\min_x \\left\\{ \\max_y f(x,y) \\right\\}$. \n",
    "\n",
    "Similarly, in the second game the payoff will be $s_2 = \\max_y \\left\\{ \\max_x f(x,y) \\right\\}$.\n",
    "\n",
    "Since player $B$, whose goal is to minimize the score, has an advantage in the first game, $s_1 \\geq s_2$ which concludes the game-theoretic proof of max-min inequality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46582626",
   "metadata": {},
   "source": [
    "# Strong Duality\n",
    "\n",
    "While weak duality is a useful result, the real strength of duality theory lies in *strong duality*. Strong duality is an LP-specific case of Von Neumann's [Minimax Theorem](https://en.wikipedia.org/wiki/Minimax_theorem) which lays out the conditions for which the max-min inequality holds with equality. Basically, it holds when \n",
    "\n",
    "Instead of proving the Minimax Theorem in the general case, we will stay topical and prove strong duality itself. That is, the Minimax Theorem as it pertains to the special case of linear programs... \n",
    "\n",
    "> **Strong Duality:** &nbsp; If the primal is feasible and bounded with optimal $x^*$ then the dual is also feasible and bounded. Furthermore, if the dual has optimum $p^*$ then $c^Tx^* = b^Tp^*$.\n",
    "<br>\n",
    "\n",
    "To prove strong duality, we require *Farkas' Lemma*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3254493",
   "metadata": {},
   "source": [
    "## Farkas' Lemma\n",
    "\n",
    "*Farkas' Lemma* belongs to the class of the *Theorems of the Alternative* — these are a class of theorems stating that exactly one of two statements holds true.\n",
    "\n",
    "The lemma simply states that a given vector $c$ is either in the cone of vectors $a_i \\ \\  \\forall i \\in I$ or there's a complete separation between the cone and the vector. That is, either $c$ is a [conic combination](https://v-poghosyan.github.io/blog/optimization/applied%20mathematics/proofs/2022/01/23/Optimization-Review-of-Linear-Algebra-and-Geometry.html#Conic-Combinations-of-$n$-Points) of the $a_i$'s or it's separated from their cone by some hyperplane. \n",
    "\n",
    "---INSERT PICTURE---\n",
    "\n",
    "We state Farkas' Lemma without offering proof, since it has such an obvious geometric interpretation.\n",
    "\n",
    "> **Farkas' Lemma:** For any vector $c$ and $a_i \\ \\ (i \\in I)$ either the first or the second statement holds:\n",
    ">\n",
    "> * $\\exists p \\geq 0$ s.t. $c = \\sum_{i \\in I} a_ip_i$\n",
    "> * $\\exists$ vector $d$ s.t. $d^Ta_i \\geq 0 \\ \\ \\forall i \\in I$ but $d^Tc < 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a81493d",
   "metadata": {},
   "source": [
    "## Proof of Strong Duality\n",
    "\n",
    "The proof is by construction. \n",
    "\n",
    "Suppose $x^*$ is a primal optimal solution. Let the set $I_{x^*} = \\{ i : a_i^Tx^* = b_i\\}$ be the set of the indices of the active constraints at $x^*$. Our goal is to construct A dual optimal solution $p^*$ s.t. $c^Tx^* = b^Tp^*$. \n",
    "\n",
    "Let $d$ be any vector that satisfies $d^Ta_i \\geq 0 \\ \\ \\forall i \\in I_{x^*}$. That is, the $d$ is a feasible direction w.r.t. to all the active constraints.\n",
    "\n",
    "Then, a small, positive $\\epsilon$-step in the direction of $d$ results in point $x^* + \\epsilon d$ that's still feasible. The fact that the step is *small* guarantees no inactive constraints are violated.\n",
    "\n",
    "Let's compare the value of the objective at $x^* + \\epsilon d$ to the value of the objective at $x^*$.\n",
    "\n",
    "By the assumption that $x^*$ is optimal, we have $c^Tx^* \\leq c^T(x^* + \\epsilon d) = c^Tx^* + \\epsilon c^Td$. Thus, $c^Td = d^Tc \\geq 0$\n",
    "\n",
    "> Note: $d^Tc$ is nothing but the *directional derivative* at the minimizer $x^*$. It is a *first-order necessary-condition (FONC)* that the *directional derivative* in any feasible direction $d$ be non-negative at any minimizer $x^*$. This is analogous to the first-derivative test for scalar-valued functions. So, this result should have been expected...\n",
    "<br>\n",
    "\n",
    "But since $d$ is a vector s.t. $d^Ta_i \\geq 0 \\ \\ \\forall i \\in I_{x^*}$ and $d^Tc \\geq 0$, then $d$ does *not* separate $c$ from the cone of the $a_i$'s. And since $d$ was arbitrary, this puts us in the setting of Farkas' Lemma. Namely, there exist *no* vectors $d$ that separate $c$ from the cone. This means the second statement in Farkas' Lemma is violated and the first must be true — $c$ must a conic combination of the $a_i$'s that are active at the minimizer. In other words, $\\exists p \\geq 0$ s.t. $c = \\sum_{i \\in I_{x^*}} p_ia_i$. \n",
    "\n",
    "But $p$ has dimension equal to only the number of active constraints at $x^*$. To be a dual variable at all, it must have dimension equal to the number of all primal constraints. We extend $p$ to $p^*$ by setting all the entries that do not correspond to the active constraints at $x^*$ to be zero. \n",
    "\n",
    "That is $p^*_i = \\begin{cases} p_i \\ \\ \\textrm{if} \\ \\  i \\in I_{x^*} \\\\ 0   \\ \\ \\textrm{if} \\ \\  i \\notin I_{x^*} \\end{cases}$. \n",
    "\n",
    "Now $A^Tp^*  = \\sum_{i} p^*_ia_i = c$, so any feasibility condition in the dual, whether it be $A^Tp \\leq c$, $A^Tp \\geq c$, or $A^Tp = c$, is satisfied. Also, \n",
    "$$b^Tp^* = \\sum_{i} b_ip_i^* = \\sum_{i \\in I_{x^*}} a_i^Tx^*p_i^* = (\\sum_{i \\in I_{x^*}} p_ia_i^T)x^* = c^Tx^* \\dagger$$\n",
    "\n",
    "It still remains to be shown that $p^*$ is dual optimal.\n",
    "\n",
    "By weak duality, $b^Tp \\leq c^Tx^*$. So, $c^Tx^*$ is an upper bound for any dual feasible solution. Recall that the dual is a maximization problem, so the optimal value must be $b^Tp^* = c^Tx^*$. Thus, by $\\dagger$ $p^*$ is dual optimal.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32d3501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
