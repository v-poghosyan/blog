{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c415992",
   "metadata": {},
   "source": [
    "# Optimization - Review of Linear Algebra and Geometry\n",
    "\n",
    "> Preliminary mathematical concepts in the study of optimization - Eigenpairs, Fundamental Subspaces, Symmetry, Spectral Decomposition, Convexity, etc.\n",
    "\n",
    "- hide: false\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: false\n",
    "- categories: ['Optimization','Applied Mathematics','Proofs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eae137",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The study of optimization can be summed up as the attempt to find those parameter(s) that optimize some objective function, if such exist. The objective function can be almost anything — cost, profit, nodes in a wireless network, distance to a destination, similarity to a target image, etc. If the objective function describes cost we may wish to minimize it. If, on the other hand, it describes profit then a natural goal would be to maximize it. \n",
    "\n",
    "The problems of minimization and maximization, summed up as *optimization* in one word, are the same problem up to a reflection with respect to the domain of the parameter(s). \n",
    "\n",
    "Formally, let the objective function be $f: \\mathbb{R^n} \\to \\mathbb{R}$, and let it have minimizer $x^* \\in \\mathbb{R^n}$. Then, by definition of minimizer, $f(x^*) \\leq f(x) \\ \\ \\forall x \\in \\mathbb{R^n}$. It follows that $-f(x^*) \\geq -f(x) \\ \\ \\forall x \\in \\mathbb{R^n}$, so $x^*$ is the maximizer for $-f$.\n",
    "\n",
    "## Model of a Convex Optimization Problem\n",
    "\n",
    "This series of posts will cover the ways in which we can solve an optimization problem of the form\n",
    "\n",
    "$\n",
    "\\textrm{minimize}: f(x)\n",
    "\\\\\n",
    "\\textrm{subject to}: x \\in \\mathcal{X}\n",
    "$\n",
    "\n",
    "where the *objective function* $f$ is a *convex function*, and the *constraint set* $\\mathcal{X}$ is a *convex set*. Importantly, we will *not* cover the ways in which we can model a real-world problem as a convex optimization problem of the above form.\n",
    "\n",
    "## Why Convex Optimization?\n",
    "\n",
    "First, let's define the *size* of an optimization problem as the dimensionality of the parameter $x$ added to the number of the problem constraints.\n",
    "\n",
    "Convex optimization problems are a class of *easy* optimization problems — problems whose time and/or space complexity grows slowly with respect to problem size.\n",
    "\n",
    "These problems are general enough to capture many scenarios of interest, even some that do not fall strictly into the convex category, but specific enough to be solvable through generic algorithms and numerical methods.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48696881",
   "metadata": {},
   "source": [
    "# Review of Linear Algebra and Geometry\n",
    "\n",
    "We start our exploration of convex optimization with a refresher on convexity and the linear algebra that's in common use in the subject. \n",
    "\n",
    "## Convexity\n",
    "\n",
    "Set convexity is defined as follows:\n",
    "\n",
    "> Definition: &nbsp; A set $C \\subseteq \\mathbb{R^d}$ is **convex** if, for all points $x_1,x_2 \\in C$ and any $\\theta \\in [0,1]$, the point $\\theta x_1 + (1-\\theta) x_2$ (i.e. the parametrized line segment between $x_1$ and $x_2$) is also in $C$.\n",
    "<br>\n",
    "\n",
    "\n",
    "### Some Operations that Preserve Convexity\n",
    "\n",
    "Shifting, scaling, and rotation (i.e. *affine* transformations) preserve convexity. Let the matrix $A$ define such a transformation, and $b$ be a shift vector. Then $C' = \\{Ax + b \\ |  \\ x \\in C \\}$ is convex provided that $C$ was convex.\n",
    "\n",
    "An *intersection* of convex sets is also convex. That is, $C' = \\{ x \\ | \\ x \\in C_1 \\cap x \\in C_2 \\}$ is convex provided that $C_1$ and $C_2$ were convex to begin with. The proof follows directly from the definition of intersection...\n",
    "\n",
    "However, *unions* of convex sets need not be convex...\n",
    "\n",
    "### Convex Hull of $n$ Points\n",
    "\n",
    "Let $x_1,x_2,...,x_n$ be $n$ points in space. The *convex hull* is the set of all points which can be written as a non-negative linear combination (also known as a *convex combination*) of these $n$ points. \n",
    "\n",
    "Formally, $\\textrm{Convex Hull} = \\{ \\theta_1 x_1 + ... + \\theta_n x_n \\ | \\ \\theta_1 + ... + \\theta_n = 1 \\ \\ \\textrm{and} \\ \\ \\theta_i \\geq 0 \\ \\ \\forall i \\}$\n",
    "\n",
    "As we vary the $\\theta$s, we generate the convex hull which can be visualized as the closed polygon formed when a rubber band is stretched around the $n$ points. \n",
    "\n",
    "> Note: A handy interactive visualization, along with the algorithm \n",
    "\n",
    "### Convex Hull of a Set\n",
    "\n",
    "Let $C$ be a non-convex set. Choose any $n$ points in this set and construct their convex hull. Now take the union of all such convex hulls of $n$ points in $C$. The result will be the smallest convex set that contains $C$, also know as its convex hull.\n",
    "\n",
    "To visualize the convex hull of a non-convex set, imagine the shape enclosed by a rubber band stretched around the non-convex set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86f5181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
