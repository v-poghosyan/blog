{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ae85da7",
   "metadata": {},
   "source": [
    "> The Lagrangian and the Karush–Kuhn–Tucker Conditions\n",
    "\n",
    "- hide: true\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: ['Optimization','Applied Mathematics','Proofs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135f170a",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Taking advantage if the geometry of linear programs, we were able to deduce that their optima occur at extreme points of the polytopal constraint set. \n",
    "\n",
    "...\n",
    "\n",
    "A characterization of optimal points for the general convex-programming case with any number of equality and inequality constraints. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6518f5",
   "metadata": {},
   "source": [
    "# The Lagrangian\n",
    "\n",
    "Consider the simple convex program with one equality constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fcfb8b",
   "metadata": {},
   "source": [
    "$\n",
    "\\begin{cases}\n",
    "\\min_x: f(x)\n",
    "\\\\\n",
    "s.t.: h(x) = 0\n",
    "\\end{cases}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7b6833",
   "metadata": {},
   "source": [
    "The key observation is that, if the convex program is feasible at all, the optima, if any exist, occur at a level set of the objective function that is tangent to the constraint boundary. The picture below illustrates this situation with a level set of the function $f(x_1,x_2) = x_1^2 e^x_2 x^2$ and a circular equality constraint. \n",
    "\n",
    "![](my_icons/lagrange-condition.png \"Optima occur on the tangent point (or space) of the level sets of the objective function and the constraint boundary\")\n",
    "<br> \n",
    "\n",
    "That is, $x^*$ is a local minimum if and only if $\\nabla_x f(x^*) = \\pm \\lambda \\nabla_x h(x^*)$ for some $\\lambda > 0$. Note that $\\lambda$ may either be added or subtracted, depending on the direction of $\\nabla_x h(x^*)$. \n",
    "\n",
    "Interestingly, this condition is general enough that for an unconstrained convex problem it reduces to $\\nabla_x f(x^*) = 0$, which is the familiar first-order necessary condition for an interior point (such as the optimal solution of an unconstrained problem) to be a local optimizer. And, since the objective functions in this post are all assumed to be convex, the second-order conditions are satisfied at any *stationary point* (a point that satisfies the first-order necessary condition). Hence, $\\nabla_x f(x^*) = 0$ is the only optimality condition we need.\n",
    "\n",
    "Since the stationary points of an unconstrained problem can be found with such relative ease, the goal is to construct an unconstrained problem related to a given constrained problem so that the former's stationary points are optimal and feasible for the constrained problem.\n",
    "\n",
    "With this in mind, we define the *Lagrangian* as the function $\\mathcal{L}(x, \\lambda) :=f(x) - \\lambda h(x)$. Now, any $(x^*, \\lambda^*)$ that satisfies $\\nabla \\mathcal{L}(x^*, \\lambda^*) = 0$ is a stationary point of the Lagrangian function, as well as an optimal, feasible solution to the constrained problem.\n",
    "\n",
    "To see this, note that $\\nabla \\mathcal{L} = [\\nabla_x  \\mathcal{L}, \\nabla_{\\lambda} \\mathcal{L}]^T = [0,0]^T$ implies $\\nabla_x f(x^*) = \\pm \\lambda \\nabla_x h(x^*)$ which is the optimality condition, and $h(x^*) = 0$ which is the feasibility condition.\n",
    "\n",
    "From the above, we see that the convention that $\\lambda > 0$ is there simply to disallow the case where $\\lambda = 0$ since that would disrespect the equality constraint $\\nabla_x f(x^*) = 0$.\n",
    "\n",
    "\n",
    "## Convex Problem with Multiple Equality Constraints\n",
    "\n",
    "For a convex program with multiple equality constraints, the condition becomes $\\nabla_x f(x^*) = \\lambda_1 \\nabla_x h_1(x^*) \\pm \\lambda_2 \\nabla_x h_2(x^*) \\pm ... \\pm \\lambda_n \\nabla_x h_n(x^*)$ with $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e4ccb4",
   "metadata": {},
   "source": [
    "# Karush-Kuhn-Tucker Conditions. \n",
    "\n",
    "KKT Conditions are a generalization of the necessary and sufficient optimality conditions. They're considered to be a certificate of optimality and are often used to verify if a particular guess is optimal or not. In many cases this beats solving the problem from scratch.\n",
    "\n",
    "Consider the following convex program with both inequality as well as equality constraints. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dc09c0",
   "metadata": {},
   "source": [
    "$\n",
    "\\begin{cases}\n",
    "\\min_x: f(x)\n",
    "\\\\\n",
    "s.t.: \\begin{aligned} &g_i(x) \\leq 0 \\ \\ \\forall i\n",
    "\\\\ \n",
    "&h_j(x) = 0 \\ \\ \\forall j\n",
    "\\end{aligned}\n",
    "\\end{cases}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba67e79",
   "metadata": {},
   "source": [
    "Let the dual variables corresponding to the inequality constraints be $\\lambda$ and those corresponding to the equality constraints be $\\mu$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d52943",
   "metadata": {},
   "source": [
    "> **KKT Conditions:** &nbsp; $x^*, (\\lambda^*, \\mu^*)$ satisfy the KKT conditions if the following hold:\n",
    "&nbsp;\n",
    "> 1. $g_i(x^*) \\leq 0$ - Primal feasibility\n",
    "> 2. $h_j(x^*) = 0$ - Primal feasibility\n",
    "> 3. $\\lambda^* \\geq 0$ - Dual feasibility\n",
    "> 4. $\\lambda^*_ig_i(x^*) = 0 \\ \\ \\forall i$ - Complementary slackness\n",
    "> 5. $\\nabla_x f(x^*) + \\sum \\lambda^*_i\\nabla_xg_i(x^*) + \\sum \\mu^*_j\\nabla_xh_j(x^*) = 0$ - Stationarity condition\n",
    "<br>\n",
    "\n",
    "> Note: If there are no inequality constraints, the KKT conditions turn into the Lagrange conditions. Then condition $5$ is simply a statement about the gradient of the Lagrangian being zero, i.e. $\\nabla \\mathcal{L} = 0$. However, as we shall soon see, it has a strong geometric interpretation as well. \n",
    "\n",
    "These are simply the conditions the primal-dual pair must meet to satisfy the KKT conditions. The following theorem is what establishes the certificate of optimality mentioned earlier.\n",
    "\n",
    "> **Theorem** &nbsp; If Strong Duality holds, then $x^*, (\\lambda^*, \\mu^*)$ are respectively primal-dual optimal if and only if they satisfy the KKT conditions. \n",
    "<br> \n",
    "\n",
    "To see how the KKT conditions are a generalization of the optimality conditions in a simple, yet elucidative case, we consider the unconstrained problem $\\min_x f(x)$ and the same problem with a single inequality constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbfa559",
   "metadata": {},
   "source": [
    "$\n",
    "\\begin{cases}\n",
    "\\min_x: f(x)\n",
    "\\\\\n",
    "s.t.: g(x) \\leq 0\n",
    "\\end{cases}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465311d2",
   "metadata": {},
   "source": [
    "**Case 1:** The unconstrained optimum is in the feasible region.\n",
    "<br> \n",
    "\n",
    "**Picture**\n",
    "\n",
    "![](my_icons/interior-optimum.png \"Case 1: Optimum is an interior point\")\n",
    "<br> \n",
    "\n",
    "Recall that $x^*$ is a local minimum of the unconstrained problem if and only if $\\nabla_x f(x^*) = 0$ and $\\nabla_{xx} f(x^*) \\succeq 0$. This is true whenever $x^*$ is an interior point. It's particularly true in the unconstrained case since all points, in particular $x^*$, are interior points.\n",
    "\n",
    "Since the inequality constraint is not active at the constrained optimum, the latter is  identified by the same conditions as the unconstrained optimum. That is, \n",
    "\n",
    "The Lagrangian of the unconstrained problem is, of course, the objective function itself.\n",
    "\n",
    "![](my_icons/interior-optimum.png \"Case 1: Optimum is an interior point\")\n",
    "<br> \n",
    "\n",
    "In this case, the optimum can be found simply by solving for $x^*$ that satisfies the above necessary and sufficient conditions.\n",
    "\n",
    "![](my_icons/exterior-optimum.png \"Case 2: Optimum is an interior point\")\n",
    "\n",
    "Take a simple convex program with one inequality constraint. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1250572",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8a7a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
