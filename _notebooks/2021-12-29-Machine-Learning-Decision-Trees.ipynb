{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Decision Trees\n",
    "\n",
    "> Heuristics for learning decision trees and their theoretical properties. \n",
    "\n",
    "- toc: true\n",
    "- hide: true\n",
    "- badges: true\n",
    "- comments: false\n",
    "- categories: ['Machine Learning','Decision Trees','Random Forests']\n",
    "- image: images/decision-tree-example.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Classification vs. Regression\n",
    "\n",
    "We start our discussion of decision trees with a definition of *classification* and *classifier*.\n",
    "\n",
    "> Definition: &nbsp; **Classification** is the process of grouping data into discrete categories (i.e. **class labels**).\n",
    "<br>\n",
    "\n",
    "We may contrast this definition with *regression* which is the process of predicting a *continous* (i.e. real or complex-valued) output. \n",
    "\n",
    "A common example of a classification problem is the sorting of emails into the binary categories of *'spam'* and *'not spam'*. However, the labels in a classification problem need not be binary â€” they may be any discrete set. Whereas a common example of regression is learning a linear (or a non-linear) function that best fits a given dataset. \n",
    "\n",
    "> Note: The line between classification and regression is sometimes blurred. For instance, *logistic regression* is a regression algorithm which outputs a prediction in the continous probability range $[0,1]$. It's commonly used with a *decision rule* which casts its output into discrete classes. Thus, even though it's a regression algorithm, it can easily be converted into a classification algorithm and is often used for classification problems in practice.\n",
    "<br>\n",
    "\n",
    "This leads us to the expected definition of a classifier, which is:\n",
    "\n",
    "> Definition: &nbsp; A **classifier** is any algorithm that performs classification.\n",
    "<br>\n",
    "\n",
    "## Decision Trees\n",
    "\n",
    "*Decision trees* are one type of classifier among many. \n",
    "\n",
    "The nodes of a decision tree correspond to the *features* of the dataset and its leaves correspond to the class labels. The paths in a decision tree corrspond to the *conjunction of features* that lead to the class labels at its leaves.\n",
    "\n",
    "To understand this, let's look at an example of a non-binary decision tree that's nonetheless very easy to understand because of the historical context of the data it's attempting to learn. \n",
    "\n",
    "**Example:**\n",
    "![](my_icons/decision-tree-example.png \"Description: Decision tree that predicts the survival chances of the passangers in the Titanic.\")\n",
    "\n",
    "The above decision tree has identified three features that best predict the chances of a given passanger of the Titanic to survive. These three features, in order of their effect on the accuracy of the prediction, are *gender*, *age*, and *sibsp* (which is the number of siblings or spouses).\n",
    "\n",
    "As we can infer from the tree, were you a passanger on the Titanic, you would've likely survived if you were either female or a male child (below the age of 9.5) with less than 3 siblings (a conjunction of features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17268/1206375028.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mFEATURE_NAMES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Sepal Length'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sepal Width'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Petal Length'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Petal Width'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "FEATURE_NAMES = ['Sepal Length', 'Sepal Width', 'Petal Length', 'Petal Width']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Simplifying Assumptions\n",
    "\n",
    "In the rest of this article, for simplicity, we will assume binary input and binary output for decision trees. That is, the training set is  ${S = \\{(x^1,y^1), ... ,(x^k, y^k)\\}}$ with ${x^i \\in \\{0,1\\}^n}$ and ${y^i \\in \\{0,1\\} \\ \\ \\forall i}$. This means that the decision tree itself is simply a binary function which also receives binary input. \n",
    "\n",
    "The task is to learn this function.\n",
    "\n",
    "## Potential Function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
