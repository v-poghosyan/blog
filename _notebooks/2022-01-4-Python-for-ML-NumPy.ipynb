{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69c00c52",
   "metadata": {},
   "source": [
    "# Python for Machine Learning - NumPy\n",
    "\n",
    "> Introduction to NumPy - Python's Feature-Rich Mathematical Library.\n",
    "\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: false\n",
    "- categories: ['Python for ML','NumPy','Machine Learning']\n",
    "- image: images/numpy-logo.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a11096",
   "metadata": {},
   "source": [
    "# Importing NumPy\n",
    "\n",
    "[NumPy](https://numpy.org/) is a scientific computing library for Python. It's an extensive collection of pre-written code that optimizes and extends, among other things, the Python array (i.e. `list`) object into an n-dimensional NumPy array called `ndarray`. It comes with a variety of tools, such as matrix operations and common mathematical functions, that enable Python to perform complex linear algebraic tasks, generate pseudo-random numbers, perform Fourier analysis, etc.\n",
    "\n",
    "We import NumPy, as we import any other library, using the `import` keyword (with or without a shorthand).\n",
    "\n",
    "```python\n",
    "import numpy\n",
    "```\n",
    " Or, alternatively:\n",
    " \n",
    "```python\n",
    "import numpy as np\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa72ef2",
   "metadata": {},
   "source": [
    "# Optimizations\n",
    "\n",
    "As we've briefly discussed in the [\"Python for Machine Learning - Pandas\"](https://v-poghosyan.github.io/blog/python%20for%20ml/pandas/machine%20learning/2021/12/28/Python-for-ML-Pandas.html#Broadcasted-and-Vectorized-Operations) post, NumPy works by delegating tasks to well-optimized C code under the hood. In this way it exploits the flexibility of Python, meanwhile bypassing the speed limitations of an *interpreted* language in favor of faster, compiled code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d7b57c",
   "metadata": {},
   "source": [
    "## Scalable Memory Representation\n",
    "\n",
    "As far as memory optimization is concerned, one of the things NumPy optimizes is data storage. \n",
    "In contrast to Python 3.x's scalable memory representation of numeric values such as integers, which can grow to accomodate a given number, NumPy stores numeric types in fixed-sized blocks of memory (such as `int32` or `int64`). This means NumPy is able to take advantage of the modern processors' low-level CPU instructions designed for fixed-sized numeric types. Another advantage of fixed-sized storage is that consecutive blocks of memory can ba allocated, which enables the libraries upon which NumPy relies to do extremely performant computations. This enforcement of fixed-sized data types is part of the  optimization strategy NumPy uses which is called vectorization.\n",
    "\n",
    "## Vectorization\n",
    "\n",
    "As already discussed in the [aforementioned post](https://v-poghosyan.github.io/blog/python%20for%20ml/pandas/machine%20learning/2021/12/28/Python-for-ML-Pandas.html#Broadcasted-and-Vectorized-Operations), *vectorization* is the process by which NumPy stores an array internally in a contiguous block of memory, and restricts its contents to only one data type. Letting Python know this data type in advance, NumPy can then skip the per-iteration type checking that Python normally does in order to speed up our code. Optimizing the array data structure in such a way enables NumPy to delegate most of the operations on such a arrays to pre-written C code under the hood. In effect, this simply means that looping occurs in C instead of Python.\n",
    "\n",
    "## Broadcasting\n",
    "\n",
    "The term *broadcasting* describes the process by which NumPy performs arithmetic operations on arrays of different dimensions. The process is usually as follows: the smaller array is “broadcast” across the larger array so that the two arrays have compatible dimensions. Broadcasting provides a means of vectorizing array operations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e90284",
   "metadata": {},
   "source": [
    "## Comparing Runtime\n",
    "To demonstrate the performance optimizations of NumPy, let's compare squaring every element of a `1,000,000`-element array and summing the results. \n",
    "\n",
    "### Using a Python List\n",
    "\n",
    "First, we will use a Python list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeb9eed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unoptimized_list = list(range(1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743a00bd",
   "metadata": {},
   "source": [
    "Squaring each element and summing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3148030c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 312 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "333332833333500000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "%time np.sum([i**2 for i in unoptimized_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6616d50",
   "metadata": {},
   "source": [
    "> Note: Even though we're using NumPy's sum method, since the input we're passing to it is a regular Python list, NumPy optimizations are not applied. \n",
    "\n",
    "<br>\n",
    "\n",
    "As we can see the whole thing took `312 ms`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cfc412",
   "metadata": {},
   "source": [
    "### Using a NumPy Array\n",
    "\n",
    "Now let's do the same with a NumPy array, which also gives us the opportunity to intruduce the syntax for defining one using a range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0026e756",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_array = np.arange(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ca4586",
   "metadata": {},
   "source": [
    "Squaring each element and summing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71d8f574",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.48 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "584144992"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time np.sum(optimized_array**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bf1138",
   "metadata": {},
   "source": [
    "Remarkably, the run-time was cut from `312 ms` to only `2.48ms`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6293ff",
   "metadata": {},
   "source": [
    "# Multi-Indexing, Filtering, and Broadcasted Operations\n",
    "\n",
    "Recall from the [Pandas article](https://v-poghosyan.github.io/blog/python%20for%20ml/pandas/machine%20learning/2021/12/28/Python-for-ML-Pandas.html) the ways in which we were able to multi-index, filter, and eliminate the need for using either Python loops or list comprehensions using broadcasted operators. Since both a Pandas `Series` and a `DataFrame` are extensions of NumPy's `ndarray`, these "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde31189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
