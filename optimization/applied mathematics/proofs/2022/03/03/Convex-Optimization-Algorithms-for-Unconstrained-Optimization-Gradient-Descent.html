<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Convex Optimization - Algorithms for Unconstrained Optimization, Gradient-Descent | Vahram Poghosyan</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Convex Optimization - Algorithms for Unconstrained Optimization, Gradient-Descent" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="GD, Smoothness, Strict Convexity, Line Search" />
<meta property="og:description" content="GD, Smoothness, Strict Convexity, Line Search" />
<link rel="canonical" href="https://v-poghosyan.github.io/blog/optimization/applied%20mathematics/proofs/2022/03/03/Convex-Optimization-Algorithms-for-Unconstrained-Optimization-Gradient-Descent.html" />
<meta property="og:url" content="https://v-poghosyan.github.io/blog/optimization/applied%20mathematics/proofs/2022/03/03/Convex-Optimization-Algorithms-for-Unconstrained-Optimization-Gradient-Descent.html" />
<meta property="og:site_name" content="Vahram Poghosyan" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-03-03T00:00:00-06:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Convex Optimization - Algorithms for Unconstrained Optimization, Gradient-Descent" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-03-03T00:00:00-06:00","datePublished":"2022-03-03T00:00:00-06:00","description":"GD, Smoothness, Strict Convexity, Line Search","headline":"Convex Optimization - Algorithms for Unconstrained Optimization, Gradient-Descent","mainEntityOfPage":{"@type":"WebPage","@id":"https://v-poghosyan.github.io/blog/optimization/applied%20mathematics/proofs/2022/03/03/Convex-Optimization-Algorithms-for-Unconstrained-Optimization-Gradient-Descent.html"},"url":"https://v-poghosyan.github.io/blog/optimization/applied%20mathematics/proofs/2022/03/03/Convex-Optimization-Algorithms-for-Unconstrained-Optimization-Gradient-Descent.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://v-poghosyan.github.io/blog/feed.xml" title="Vahram Poghosyan" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-QB9Q6T3YNL"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-QB9Q6T3YNL');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Vahram Poghosyan</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Convex Optimization - Algorithms for Unconstrained Optimization, Gradient-Descent</h1><p class="page-description">GD, Smoothness, Strict Convexity, Line Search</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-03-03T00:00:00-06:00" itemprop="datePublished">
        Mar 3, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      13 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#Optimization">Optimization</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#Applied Mathematics">Applied Mathematics</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#Proofs">Proofs</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/v-poghosyan/blog/tree/master/_notebooks/2022-03-03-Convex Optimization-Algorithms-for-Unconstrained-Optimization-Gradient-Descent.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/v-poghosyan/blog/master?filepath=_notebooks%2F2022-03-03-Convex+Optimization-Algorithms-for-Unconstrained-Optimization-Gradient-Descent.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/v-poghosyan/blog/blob/master/_notebooks/2022-03-03-Convex Optimization-Algorithms-for-Unconstrained-Optimization-Gradient-Descent.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#PLAN">PLAN </a></li>
<li class="toc-entry toc-h1"><a href="#Introduction">Introduction </a></li>
<li class="toc-entry toc-h1"><a href="#The-Gradient-Descent-Algorithm">The Gradient Descent Algorithm </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Idea-1---Greedy-Choice-of-Direction">Idea 1 - Greedy Choice of Direction </a></li>
<li class="toc-entry toc-h2"><a href="#Idea-2---Greedy-Choice-of-Next-Iterate">Idea 2 - Greedy Choice of Next Iterate </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Important-Questions-in-Analysis">Important Questions in Analysis </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Initialization">Initialization </a></li>
<li class="toc-entry toc-h2"><a href="#Fixed-Step-Size-GD">Fixed Step-Size GD </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Simple-Analysis-of-Fixed-Step-Size-GD">Simple Analysis of Fixed Step-Size GD </a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Smoothness-and-Strong-Convexity">Smoothness and Strong Convexity </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Quadratic-Bounds">Quadratic Bounds </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-03-03-Convex Optimization-Algorithms-for-Unconstrained-Optimization-Gradient-Descent.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="PLAN">
<a class="anchor" href="#PLAN" aria-hidden="true"><span class="octicon octicon-link"></span></a>PLAN<a class="anchor-link" href="#PLAN"> </a>
</h1>
<ol>
<li>Unconstrained algorithms 
<del>2. Oracle Access Model of order 1</del>
<del>3. Develop GD from two perspectives - linear and quadratic</del>
</li>
<li>Run GD on model problems x^2 and |x|</li>
<li>Develop the notion of M-smooth and m-strongly convex based on step 4</li>
<li>
<p>Analyze the performance of GD</p>
</li>
<li>
<p>Develop Accelerated GD</p>
</li>
<li>Develop Subgradient Descent</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Introduction">
<a class="anchor" href="#Introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction<a class="anchor-link" href="#Introduction"> </a>
</h1>
<p><strong><em>Gradient descent (GD)</em></strong> is a powerful, yet incredibly simple, optimization algorithm. We can think of it as a <strong><em>greedy algorithm</em></strong> in the setting of continuous optimization. That is, it is our best, local attempt at optimization given only limited information about the objective $f(x)$, and having limited computational power. For now, we focus on the simpler case of unconstrained optimization in order to develop the key algorithmic ideas. Later on, perhaps in a different post, we will explore modifications to gradient descent that make it suitable for constrained optimization.</p>
<h1 id="The-Gradient-Descent-Algorithm">
<a class="anchor" href="#The-Gradient-Descent-Algorithm" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Gradient Descent Algorithm<a class="anchor-link" href="#The-Gradient-Descent-Algorithm"> </a>
</h1>
<p>As all iterative algorithms, gradient descent relies on <strong><em>initialization</em></strong> and an <strong><em>update step</em></strong>. In this section, we explore two ideas that play a key role in developing the GD algorithm.</p>
<h2 id="Idea-1---Greedy-Choice-of-Direction">
<a class="anchor" href="#Idea-1---Greedy-Choice-of-Direction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Idea 1 - Greedy Choice of Direction<a class="anchor-link" href="#Idea-1---Greedy-Choice-of-Direction"> </a>
</h2>
<p>Let $x$ be the initial iterate, and let the update be given by:
<br>
$$x^+ = x + \eta d$$ 
<br></p>
<p>for some directional unit-vector $d$ and <strong><em>step-size</em></strong> parameter $\eta &gt; 0$.</p>
<p>We base the algorithm on the assumption that the linear approximation of the objective at a the next iterate $x^+$ is a good-enough estimate of its true value at $x^+$.</p>
<p>That is:</p>
<p><br>

$$f(x^+) = f(x + \eta d) \approx f(x) + \eta \nabla f(x)^T d \ \ \forall d \tag{1.1}$$

<br></p>
<p>Immediately, a locally optimal choice presents itself to us. Since we wish to minimize $f(x)$, it would be wise to insist that the objective at $x^+$ improves or, at least, does not worsen.</p>
<p>That is, we insist:</p>
<p><br>

$$f(x^+) \approx f(x) + \eta \nabla f(x)^T d \leq f(x) \tag{1.2}$$

<br></p>
<p>And, since we are greedy in our approach, we wish to make $f(x^+)$ as small as possible. Since, on the RHS, $f(x)$ is fixed and $\eta &gt; 0$, this amounts to minimizing the scaled inner-product $\nabla f(x)^Td$. To that end, we choose $d$ opposite and parallel to the gradient, i.e. $d = - \frac{\nabla f(x)}{||\nabla f(x)||_2}$.</p>
<p>The update step becomes:</p>
<p><br>

$$x^+ = x - \eta \frac{\nabla f(x)}{||\nabla f(x)||_2}$$

<br></p>
<p>By re-labeling, $\eta$ can absorb the normalization constant. This obtains the gradient descent update step as it's often introduced in the textbooks:</p>
<p><br>

$$x^+ = x - \eta \nabla f(x) \tag{1.3}$$

<br></p>
<p>This makes intuitive sense because the negative gradient direction is the direction in which the objective decreases most. So, it's only natural that the update should take us in this most enticing direction.</p>
<h2 id="Idea-2---Greedy-Choice-of-Next-Iterate">
<a class="anchor" href="#Idea-2---Greedy-Choice-of-Next-Iterate" aria-hidden="true"><span class="octicon octicon-link"></span></a>Idea 2 - Greedy Choice of Next Iterate<a class="anchor-link" href="#Idea-2---Greedy-Choice-of-Next-Iterate"> </a>
</h2>
<p>Instead of defining the update step $x^+ = x + \eta d$ and then choosing the locally optimal direction $d$ greedily, we can choose the update step and the direction, both, in one fell swoop.</p>
<p>Starting from the linear approximation:</p>
<p><br>
$$
f(y) \approx f(x) + \nabla f(x)^T(y - x) \ \ \forall y \tag{2.1}
$$
<br></p>
<p>We can now insist, in a greedy fashion, that the next iterate $x^+$ be the minimizer of the linear approximation. That is, we insist:</p>
<p><br>
$$
x^+ = \arg \min_y f(x) + \nabla f(x)^T(y - x) \tag{2.2}
$$
<br></p>
<p>But since the linear approximation is unbounded below, this obtains $x^+ = \pm \infty$. To avoid this problem, we introduce a parametrized penalty term that prevents $x^+$ from venturing too far from the current iterate $x$. That is:</p>
<p><br>
$$
x^+ = \arg \min_y f(x) + \nabla f(x)^T(y - x) + \eta ||y - x||_2^2 \tag{2.3}
$$
<br></p>
<p>Now, since the RHS is a a simple quadratic in $y$, it has a unique minimizer which can be found by using the <strong><em>unconstrained optimality condition</em></strong>. This just means taking the gradient of the RHS w.r.t. the optimization variable $y$, setting it to zero, and then solving for the unique root. This obtains:</p>
<p><br>

$$x^+ = x - \frac{1}{2 \eta} \nabla f(x)$$

<br></p>
<p>By re-labeling, we, once again, get the canonical form of the GD update step $(1.3)$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Important-Questions-in-Analysis">
<a class="anchor" href="#Important-Questions-in-Analysis" aria-hidden="true"><span class="octicon octicon-link"></span></a>Important Questions in Analysis<a class="anchor-link" href="#Important-Questions-in-Analysis"> </a>
</h1>
<p>Given the ease with which we came up with the algorithm, we should ask ourselves the following questions:</p>
<ol>
<li>Is GD sensitive to initialization?</li>
<li>Is GD guaranteed to converge for all step-sizes?</li>
<li>How should we choose a step-size that guarantees convergence? </li>
<li>What's the rate of convergence of GD? Does the rate depend on step-size? Does it depend on properties of the objective function?</li>
<li>How should we choose a step-size that maximizes convergence rate?</li>
</ol>
<p>We will shortly explore each of these questions and more. However, before doing so, it's worth taking a bird's eye look at the problem of convex optimization itself.</p>
<p>Perhaps the most important question to ask ourselves is this: does gradient descent's convergence rate, for an optimally chosen step-size, give a taxonomy of easier-to-harder problems within the scope of convex optimization? The answer, as it turns out, is <em>yes</em>.</p>
<h2 id="Initialization">
<a class="anchor" href="#Initialization" aria-hidden="true"><span class="octicon octicon-link"></span></a>Initialization<a class="anchor-link" href="#Initialization"> </a>
</h2>
<p>From this point on, we will limit our discussion to convex objectives in order to eliminate the possibility of strictly <strong><em>local optimizers</em></strong> and <strong><em>inflection points</em></strong>, both of which GD, by construction, can get stuck at given a badly chosen initial point. This ensures the only <strong><em>stationary points</em></strong>, points at which $\nabla f(x) = 0$ and the GD update makes no further progress, are global minimizers. On convex functions GD, as we will soon discover, has a convergence guarantee for all step-sizes independently of initialization.</p>
<h2 id="Fixed-Step-Size-GD">
<a class="anchor" href="#Fixed-Step-Size-GD" aria-hidden="true"><span class="octicon octicon-link"></span></a>Fixed Step-Size GD<a class="anchor-link" href="#Fixed-Step-Size-GD"> </a>
</h2>
<p>To kickstart our analysis of GD, we consider the fixed step-size algorithm first. Let's take two quintessential convex problems in $\mathbb{R}$, $f(x) = x^2$ and $h(x) = |x|$, and analyze GD's performance on these objectives.</p>
<h3 id="Simple-Analysis-of-Fixed-Step-Size-GD">
<a class="anchor" href="#Simple-Analysis-of-Fixed-Step-Size-GD" aria-hidden="true"><span class="octicon octicon-link"></span></a>Simple Analysis of Fixed Step-Size GD<a class="anchor-link" href="#Simple-Analysis-of-Fixed-Step-Size-GD"> </a>
</h3>
<p>First, let's run the algorithm on $h(x) = |x|$ for $x \in \mathbb{R}$.</p>
<p>Since $|x|$ is non-differentiable at $x = 0$, the gradient has a discontinuity at $x = 0$. Non-differentiability, such as this, will eventually lead us to introduce the notion of <strong><em>sub-gradients</em></strong>, but for now we can get away with using the discontinuous gradient:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
h'(x) = 
\begin{cases} 
\begin{aligned} 
-1 \ &amp;\textrm{if $x &lt; 0$} \\ 
1 \ &amp;\textrm{if $x &gt; 0$} 
\end{aligned}
\end{cases}
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then, for a fixed $\eta &gt; 0$, the update step is:</p>
<p><br>

$$x^+ = x \pm \eta$$

<br></p>
<p>where the sign of $\eta$ depends on where the previous iterate, $x$, falls inside the domain $(-\infty, 0) \cup (0, \infty)$.</p>
<p>Now, switching our attention to $f(x) = x^2$, we compute its GD update as follows. We compute the gradient as $f'(x) = 2x$ which leads to the fixed step-size update:</p>
<p><br>

$$x^+ = x - 2\eta x$$

<br></p>
<p>Note that $x^* = 0$ is the unique optimizer of both $f(x)$ and $h(x)$. With this in mind, there are two key observations to make.</p>
<p>The first is that, for $x$ far away from $x^* = 0$, the update, $2\eta x$, is large in magnitude. So, if the iterate is far from the optimizer, GD makes fast progress towards it.</p>
<p>The second observation is that, as $x \rightarrow x^*$, the update becomes small in magnitude. So, as the iterate comes close to the optimizer, GD takes smaller and smaller steps which converge to $0$ in a summable way. This means, we can get the sub-optimality $|f(x) - f(x^*)|$ to be $\epsilon$-arbitrarily small for any fixed step-size $\eta$.</p>
<p>Neither of these observations hold for GD on $h(x) = |x|$ since the update $\eta$ is fixed regardless of the Euclidean distance between $x$ and $x^* = 0$. In particular, this means GD is not fast for $x$ far away from $x^*$ and does not slow down as $x$ nears $x^*$. Arbitrary accuracy is, also, impossible in the setting of a fixed step-size $\eta$. The iterates eventually cycle between $x^T - \eta$ and $x^T + \eta$ where $x^T$ is in the open $\eta$-neighborhood of $x^* = 0$, so the sub-optimality also cycles between two values which depend on the choice of $\eta$. That is, the sub-optimality cannot be $\epsilon$-arbitrary small for a fixed choice of $\eta$. To be clear, there is still convergence but it's slow and not arbitrarily accurate. Arbitrary accuracy for such problems as this can only be achieved by choosing a sequence of diminishing step-sizes $\{ \eta_t \}_{t=1}^T$ which help diminish the update since the gradient itself is non-diminishing. Of course, the sequence must be chosen with care since it's possible to <em>'run out of steam'</em> before reaching the optimizer.</p>
<p>We say GD on $f(x) = x^2$ enjoys the <strong><em>self-tuning property</em></strong>, whereas GD on $h(x) = |x|$ does not. This speaks to the fact that the self-tuning is a property of the objective functions, rather than GD itself.</p>
<p>As an overview of the theory we will soon develop, functions <em>like</em> $x^2$ will all have the self-tuning property while functions <em>like</em> $|x|$ will not. This is what ends up introducing a taxonomy of easier-to-harder convex optimization problems. What it means, precisely, to be <em>like</em> $x^2$ or $|x|$ will be made rigorous in the next few sections.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Smoothness-and-Strong-Convexity">
<a class="anchor" href="#Smoothness-and-Strong-Convexity" aria-hidden="true"><span class="octicon octicon-link"></span></a>Smoothness and Strong Convexity<a class="anchor-link" href="#Smoothness-and-Strong-Convexity"> </a>
</h1>
<p>As we saw above, gradient descent with a fixed step-size behaved much better on $f(x) = x^2$ than on $h(x) = |x|$. Since both of these problems are convex, $x^2$ must have additional properties not shared by $|x|$ that make it more amenable to optimization by GD. These properties turn out to be <strong><em>smoothness</em></strong> and <strong><em>strong convexity</em></strong>. We will see that these properties provide insight into choosing the best fixed-step size which guarantees faster convergence of GD.</p>
<p>We can start by asking ourselves what makes the two quintessential functions $f(x) = x^2$ and $h(x) = |x|$ different from one another. Since the GD update step relies on the gradient, it helps thinking in terms of the differences of the gradients instead of the objective functions themselves.</p>
<p>The first difference of note is that $|x|$ has a discontinuity at $x = 0$ that's not present in $x^2$. At a point of discontinuity the gradient experiences an abrupt jump. So, in general, jumps in the gradient must pose a problem for GD.</p>
<p>The second thing to note is that $|x|$ is flat compared to $x^2$. In flat regions, the gradient is constant. So, in general, constant regions in the gradient must pose a problem for GD.</p>
<p>Both of these scenarios can be ruled out with a <a href="https://en.wikipedia.org/wiki/Lipschitz_continuity"><strong><em>Lipschitz condition</em></strong></a> on the gradient. Lipschitz conditions are both regularity conditions and growth conditions, so they rule out abrupt jumps and contain the growth of the gradient.</p>
<p>We are ready to define the two properties mentioned in the beginning of this section.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p><strong>Smoothness:</strong>   We say a function $f(x)$ is <strong><em>M-smooth</em></strong> if its gradient is <strong><em>M-Lipschitz</em></strong>. That is, if:<br>

$$\exists M &gt; 0 \ \ s.t. \ \ ||\nabla f(x) - \nabla f(y)||_2 \leq M||x-y||_2 \ \ \forall x,y$$

<br></p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is a universal upper-bound on the change in gradient which rules out jumps.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p><strong>Strong Convexity:</strong>   We say a function $f(x)$ is <strong><em>m-strongly-convex</em></strong> if:<br>

$$\exists m &gt; 0 \ \ s.t. \ \ ||\nabla f(x) - \nabla f(y)||_2 \geq m||x-y||_2 \ \ \forall x,y$$

<br></p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is a universal lower-bound on the change in gradient which rules out the possibility of a constant gradient.</p>
<p>In particular, an $M$-smooth, and $m$-strongly-convex function $f(x)$ has the property that:</p>
<p><br>

$$m||x-y||_2 \leq ||\nabla f(x) - \nabla f(y)||_2 \leq M||x-y||_2 \ \ \forall x,y \tag{3.1}$$

<br></p>
<p>For a twice-differentiable function, there's a more compact way to express these properties using the hessian. It makes use of an ordering on matrices introduced by matrix <a href="https://en.wikipedia.org/wiki/Definite_matrix"><strong><em>definiteness</em></strong></a>.</p>
<p><br>

$$||\nabla f(x) - \nabla f(y)||_2 \leq M||x-y||_2 \ \ \forall x,y$$


$$\iff$$


$$||\nabla^2 f(x)||_2 \leq M \ \ \forall x$$


$$\iff$$


$$\nabla^2 f(x) \preceq  MI \ \ \forall x \tag{4.1}$$

<br></p>
<p>The first equivalence is by the <a href="https://en.wikipedia.org/wiki/Mean_value_theorem"><strong><em>Mean Value Theorem</em></strong></a> and the second follows from the definition of <strong><em>matrix norm</em></strong>.</p>
<p>Line $(3.1)$ should be read as <em>'the maximum eigenvalue of the hessian $\nabla^2 f(x)$ is $M$'</em>.</p>
<p>By a symmetric argument, we also have:</p>
<p><br>

$$\nabla^2 f(x) \succeq mI \ \ \forall x \tag{4.2}$$

<br></p>
<p>Which should be read as <em>'the minimum eigenvalue of the hessian $\nabla^2 f(x)$ is $m$'</em>.</p>
<p>Together, $(4.1)$ and $(4.2)$ give the analog of $(3.1)$ for twice-differentiable $M$-smooth and $m$-strongly-convex functions:</p>
<p><br>

$$mI \preceq \nabla^2 f(x) \preceq MI \ \ \forall x \tag{3.2}$$

<br></p>
<p>Since the hessian represents the curvature of the function, $(3.2)$ is a two-sided bound on the curvature of $f(x)$. So, we see that smoothness and strong convexity also regulate function shape itself. The lower-bound rules out flatness, while the upper-bound rules out discontinuities like corners and cusps.</p>
<h2 id="Quadratic-Bounds">
<a class="anchor" href="#Quadratic-Bounds" aria-hidden="true"><span class="octicon octicon-link"></span></a>Quadratic Bounds<a class="anchor-link" href="#Quadratic-Bounds"> </a>
</h2>
<p>Smoothness and strong-convexity</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Ruling out discontinuities should involve a regularity condition, whereas ruling out flatness should</p>
<p>If $f$ is $M$-smooth, then we have the tightest possible point-wise quadratic upper bound as:</p>
<p><br>

$$f(y) \leq f(x) + \nabla f(x)^T(y-x) + \frac{M}{2} ||y-x||_2^2 \ \ \forall y$$

<br></p>
<p>How does this help us choose step size in a better way?</p>
<p>Plug the step $x^+ = x - \eta \nabla f(x)$ into the upper bound:</p>
<p><br>
$$
\begin{aligned}
f(x^+) &amp;\leq f(x) + \nabla f(x)^T(\eta \nabla f(x)) + \frac{M}{2} ||\eta \nabla f(x)||_2^2 \\
\iff f(x^+) &amp;\leq f(x) +  \eta || \nabla f(x) ||_2^2 + \frac{M \eta^2}{2} ||\nabla f(x)||_2^2
\end{aligned}
$$
<br></p>
<p>But the RHS is a quadratic function in $\eta$, the step-size. So, the upper bound on the next iterate $f(x^+)$, and consequently also the next iterate itself, can be minimized w.r.t. $\eta$. Essentially, we trust the upper bound is a good quadratic approximation and choose its minimizer as the next iterate. Just like in NM we trust the quadratic estimate, and set its minimizer as the next iterate. But here, we require no second-order information about the function.</p>
<p>The non-NM view is this. We have a fixed $x$ and the quadratic upper bound at that $x$. Any next iterate will be smaller than the qudratic UB <em>at</em> that iterate. So we choose a step size that minimizes this UB. This guarantees $f(x^+) \leq$ min of UB which is the tightest guarantee we can get on $f(x^+)$ with the information at hand. So we, once again, do the locally optimal thing and choose that.</p>
<p>The best choice turns out to be $\eta = \frac{1}{M}$</p>
<p>FOR FUNCTIONS THAT ARE M SMOOTH M WORKS FOR EVERY POINT. WHEREAS WE ARE SHIT OUT OF LUCK IF SUCH AN M DOESN'T EXIST. THEN WE DON'T HAVE THIS UB. IT IS THEN THAT WE USE EITHER NM OR QUASI-NM.</p>
<p>||||</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this analysis, we're only concerned about convex, unconstrained objectives $f(x)$. So, by definition of convexity, the linear approximation is actually a lower-bound of the true value at $x^+$.</p>
<p><br>

$$f(x^+) \geq f(x) + \eta \nabla f(x)^T d \ \ \forall d \tag{1.2}$$

<br></p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="v-poghosyan/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-dark"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/optimization/applied%20mathematics/proofs/2022/03/03/Convex-Optimization-Algorithms-for-Unconstrained-Optimization-Gradient-Descent.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Personal blog about Machine Learning, Data Science, Mathematics, Software Engineering, and various other topics. Created by Vahram Poghosyan, © 2021 - Present.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/v-poghosyan" target="_blank" title="v-poghosyan"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/Vahram31680593" target="_blank" title="Vahram31680593"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
