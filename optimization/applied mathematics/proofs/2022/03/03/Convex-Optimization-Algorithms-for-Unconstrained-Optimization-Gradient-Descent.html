<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Convex Optimization - Algorithms for Unconstrained Optimization, Gradient-Descent | Vahram Poghosyan</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Convex Optimization - Algorithms for Unconstrained Optimization, Gradient-Descent" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="GD, Smoothness, Strict Convexity, Line Search" />
<meta property="og:description" content="GD, Smoothness, Strict Convexity, Line Search" />
<link rel="canonical" href="https://v-poghosyan.github.io/blog/optimization/applied%20mathematics/proofs/2022/03/03/Convex-Optimization-Algorithms-for-Unconstrained-Optimization-Gradient-Descent.html" />
<meta property="og:url" content="https://v-poghosyan.github.io/blog/optimization/applied%20mathematics/proofs/2022/03/03/Convex-Optimization-Algorithms-for-Unconstrained-Optimization-Gradient-Descent.html" />
<meta property="og:site_name" content="Vahram Poghosyan" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-03-03T00:00:00-06:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Convex Optimization - Algorithms for Unconstrained Optimization, Gradient-Descent" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-03-03T00:00:00-06:00","datePublished":"2022-03-03T00:00:00-06:00","description":"GD, Smoothness, Strict Convexity, Line Search","headline":"Convex Optimization - Algorithms for Unconstrained Optimization, Gradient-Descent","mainEntityOfPage":{"@type":"WebPage","@id":"https://v-poghosyan.github.io/blog/optimization/applied%20mathematics/proofs/2022/03/03/Convex-Optimization-Algorithms-for-Unconstrained-Optimization-Gradient-Descent.html"},"url":"https://v-poghosyan.github.io/blog/optimization/applied%20mathematics/proofs/2022/03/03/Convex-Optimization-Algorithms-for-Unconstrained-Optimization-Gradient-Descent.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://v-poghosyan.github.io/blog/feed.xml" title="Vahram Poghosyan" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-QB9Q6T3YNL"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-QB9Q6T3YNL');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Vahram Poghosyan</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Convex Optimization - Algorithms for Unconstrained Optimization, Gradient-Descent</h1><p class="page-description">GD, Smoothness, Strict Convexity, Line Search</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-03-03T00:00:00-06:00" itemprop="datePublished">
        Mar 3, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      8 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#Optimization">Optimization</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#Applied Mathematics">Applied Mathematics</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#Proofs">Proofs</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/v-poghosyan/blog/tree/master/_notebooks/2022-03-03-Convex Optimization-Algorithms-for-Unconstrained-Optimization-Gradient-Descent.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/v-poghosyan/blog/master?filepath=_notebooks%2F2022-03-03-Convex+Optimization-Algorithms-for-Unconstrained-Optimization-Gradient-Descent.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/v-poghosyan/blog/blob/master/_notebooks/2022-03-03-Convex Optimization-Algorithms-for-Unconstrained-Optimization-Gradient-Descent.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#PLAN">PLAN </a></li>
<li class="toc-entry toc-h1"><a href="#Introduction">Introduction </a></li>
<li class="toc-entry toc-h1"><a href="#The-Gradient-Descent-Algorithm">The Gradient Descent Algorithm </a></li>
<li class="toc-entry toc-h1"><a href="#Oracle-Access-Model">Oracle Access Model </a></li>
<li class="toc-entry toc-h1"><a href="#Important-Questions">Important Questions </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Simple-Examples-of-Gradient-Descent">Simple Examples of Gradient Descent </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-03-03-Convex Optimization-Algorithms-for-Unconstrained-Optimization-Gradient-Descent.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="PLAN">
<a class="anchor" href="#PLAN" aria-hidden="true"><span class="octicon octicon-link"></span></a>PLAN<a class="anchor-link" href="#PLAN"> </a>
</h1>
<ol>
<li>Unconstrained algorithms </li>
<li>Oracle Access Model of order 1</li>
<li>Develop GD from two perspectives - linear and quadratic</li>
<li>Run GD on model problems x^2 and |x|</li>
<li>Develop the notion of M-smooth and m-strongly convex based on step 4</li>
<li>
<p>Analyze the performance of GD</p>
</li>
<li>
<p>Develop Accelerated GD</p>
</li>
<li>Develop Subgradient Descent</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Introduction">
<a class="anchor" href="#Introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction<a class="anchor-link" href="#Introduction"> </a>
</h1>
<p><strong><em>Gradient descent (GD)</em></strong> is a powerful, yet incredibly simple, algorithm for unconstrained, convex optimization. We can think of it as the analog of a <strong><em>greedy algorithm</em></strong> in the setting of convex, continuous optimization. That is, it is our attempt to do best locally given only limited information about the objective $f$, and limited computational power.</p>
<h1 id="The-Gradient-Descent-Algorithm">
<a class="anchor" href="#The-Gradient-Descent-Algorithm" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Gradient Descent Algorithm<a class="anchor-link" href="#The-Gradient-Descent-Algorithm"> </a>
</h1>
<p>As all iterative algorithms, gradient descent relies on <strong><em>initialization</em></strong> and an <strong><em>update step</em></strong>.</p>
<p>Let $x$ be the initial iterate, and let the update be given by $x^+ = x + \eta d$ for some directional unit-vector $d$ and <strong><em>step-size</em></strong> parameter $\eta &gt; 0$.</p>
<p>We base the algorithm on the assumption that the linear approximation of the objective at a the next iterate $x^+$ is a good-enough local approximation of its true value at $x^+$.</p>
<p>That is:</p>
<p><br>

$$f(x^+) = f(x + \eta d) \approx f(x) + \eta \nabla f(x)^T d \ \ \forall d \tag{1.1}$$

<br></p>
<p>Immediately, a locally optimal choice presents itself to us. Since we wish to minimize $f$, it would be wise to insist that the objective at $x^+$ improves or, at the very least, does not worsen.</p>
<p>That is, we insist:</p>
<p><br>

$$f(x^+) \approx f(x) + \eta \nabla f(x)^T d \leq f(x) \tag{1.2}$$

<br></p>
<p>In fact, since we are greedy in our approach, it's in our interest to get $f(x^+)$ to be as small as possible. Since $f(x)$ is fixed and $\eta &gt; 0$, this amounts to minimizing the scaled inner-product $\nabla f(x)^Td$. To that end, we choose $d$ opposite and parallel to the gradient, i.e. $d = - \frac{\nabla f(x)}{||\nabla f(x)||_2}$.</p>
<p>The update step becomes:</p>
<p><br>

$$x^+ = x - \eta \frac{\nabla f(x)}{||\nabla f(x)||_2}$$

<br></p>
<p>By re-labeling, $\eta$ absorbs the normalization constant obtaining the final gradient descent update step:</p>
<p><br>

$$x^+ = x - \eta \nabla f(x) \tag{1.3}$$

<br></p>
<p>This makes intuitive sense because the negative gradient direction is the direction in which the objective decreases most. So, it's only natural that the update should take us in this most enticing direction.</p>
<p>It's worth exploring another avenue leading to the same GD update rule. Instead of defining the step $x^+ = x + \eta d$ and then determining the direction $d$, we can determine the step and the direction in one fell swoop.</p>
<p>Starting from the linear approximation:</p>
<p><br>
$$
f(y) \approx f(x) + \nabla f(x)^T(y - x) \ \ \forall y \tag{2.1}
$$
<br></p>
<p>We can insist, in a greedy fashion, that the next iterate $x^+$ be the minimizer of the linear approximation. That is, we insist:</p>
<p><br>
$$
x^+ = \arg \min_y f(x) + \nabla f(x)^T(y - x)
$$
<br></p>
<p>But since the linear approximation is unbounded below, this obtains $x^+ = \pm \infty$. So, we introduce a parametrized penalty term that prevents $x^+$ from venturing too far from the current iterate $x$. That is, we augment the linear approximation into:</p>
<p><br>
$$
x^+ = \arg \min_y f(x) + \nabla f(x)^T(y - x) + \eta ||y - x||_2^2
$$
<br></p>
<p>Now, since the RHS is a a simple quadratic, it has a unique minimum which can be found by using the <strong><em>unconstrained optimality condition</em></strong>. This just means taking the gradient of the RHS w.r.t. the optimization variable $y$, setting it to zero, and solving for the roots.</p>
<p><br>
$$
\begin{aligned}
\nabla f(x) &amp;+ 2 \eta (y - x) = 0 \\ \\
\iff 2 \eta y &amp;= 2 \eta x - \nabla f(x) \\
\iff y &amp;= x - \frac{1}{2 \eta} \nabla f(x)
\end{aligned}
$$
<br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Oracle-Access-Model">
<a class="anchor" href="#Oracle-Access-Model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Oracle Access Model<a class="anchor-link" href="#Oracle-Access-Model"> </a>
</h1>
<p>With the foresight</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Important-Questions">
<a class="anchor" href="#Important-Questions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Important Questions<a class="anchor-link" href="#Important-Questions"> </a>
</h1>
<p>Given the ease with which we came up with the algorithm, we should ask ourselves the following questions.</p>
<ol>
<li>Is GD guaranteed to converge for all step-sizes? </li>
<li>How should we choose a step-size that guarantees convergence? </li>
<li>What's the rate of convergence of GD? Does the rate depend on step-size? Does it depend on properties of the objective function?</li>
<li>How should we choose a step-size that maximizes convergence rate?</li>
</ol>
<p>We will explore each of this questions, and more, shortly. However, before doing so, it's worth taking a bird's eye look at the problem of convex optimization itself. Perhaps the most important question to ask is this: does gradient descent's convergence rate, for an optimally chosen step-size, give a taxonomy of easier-to-harder problems within the scope of convex optimization? The answer, as it turns out, is <em>yes</em>.</p>
<p>Let's start by running fixed step-size GD on two quintessential convex problems in $\mathbb{R}$, $f(x) = x^2$ and $h(x) = |x|$.</p>
<h2 id="Simple-Examples-of-Gradient-Descent">
<a class="anchor" href="#Simple-Examples-of-Gradient-Descent" aria-hidden="true"><span class="octicon octicon-link"></span></a>Simple Examples of Gradient Descent<a class="anchor-link" href="#Simple-Examples-of-Gradient-Descent"> </a>
</h2>
<p>First, let's run the algorithm on $h(x) = |x|$ for $x \in \mathbb{R}$.</p>
<p>Since $|x|$ is non-differentiable at $x = 0$, the gradient has a discontinuity at $x = 0$. Non-differentiability, such as this, will eventually lead us to introduce the notion of <strong><em>sub-gradients</em></strong>, but for now we can get away with using the discontinuous gradient:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
h'(x) = 
\begin{cases} 
\begin{aligned} 
-1 \ &amp;\textrm{if $x &lt; 0$} \\ 
1 \ &amp;\textrm{if $x &gt; 0$} 
\end{aligned}
\end{cases}
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then, for a fixed $\eta &gt; 0$, the update step is:</p>
<p><br>

$$x^+ = x \pm \eta$$

<br></p>
<p>where the sign of $\eta$ depends on where the previous iterate, $x$, falls inside the domain $(-\infty, 0) \cup (0, \infty)$.</p>
<p>Now, switching our attention to $f(x) = x^2$, we compute its GD update as follows. We compute the gradient as $f'(x) = 2x$ which leads to the fixed step-size update:</p>
<p><br>

$$x^+ = x - 2\eta x$$

<br></p>
<p>Note that $x^* = 0$ is the unique optimal solution to both $f(x)$ and $h(x)$. With this in mind, there are two key observations to make.</p>
<p>The first is that, for $x$ far away from $x^* = 0$, the update, $2\eta x$, is large in magnitude. So, if the iterate is far from the optimal solution, GD makes fast progress towards the optimal. The second observation is that, as $x \rightarrow x^*$, the update becomes small in magnitude. So, as the iterate comes close to the optimal, GD takes smaller and smaller steps which converge to $0$ in a summable way. This means, we can get the sub-optimality $|f(x) - f(x^*)|$ to be $\epsilon$-arbitrarily small for any fixed step-size $\eta$.</p>
<p>Neither of these observations hold for GD on $h(x) = |x|$ since the update $\eta$ is fixed regardless of the Euclidean distance between $x$ and $x^* = 0$. In particular, this means GD is not fast for $x$ far away from $x^*$ and does not slow down as $x$ nears $x^*$. Arbitrary accuracy is, also, impossible in this setting for a fixed step-size $\eta$. The iterates eventually cycle between $x^T - \eta$ and $x^T + \eta$ where $x^T$ is in the open $\eta$-neighborhood of $x^* = 0$, so the sub-optimality also cycles between two values and depends on the choice of $\eta$.</p>
<p>We say GD on $f(x) = x^2$ enjoys the <strong><em>self-tuning property</em></strong>, whereas GD on $h(x) = |x|$ does not. This speaks to the fact that the self-tuning is a property of the objective functions, rather than GD itself. In a sense, functions <em>like</em> $x^2$ will all have self-tuning while functions <em>like</em> $|x|$ do not and this is what introduces a taxonomy of easier-to-harder convex optimization problems. What it means, precisely, to be <em>like</em> $x^2$ or $|x|$ will be made rigorous in the next few sections.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If $f$ is $M$-smooth, then we have the tightest possible point-wise quadratic upper bound as:</p>
<p><br>

$$f(y) \leq f(x) + \nabla f(x)^T(y-x) + \frac{M}{2} ||y-x||_2^2 \ \ \forall y$$

<br></p>
<p>How does this help us choose step size in a better way?</p>
<p>Plug the step $x^+ = x - \eta \nabla f(x)$ into the upper bound:</p>
<p><br>
$$
\begin{aligned}
f(x^+) &amp;\leq f(x) + \nabla f(x)^T(\eta \nabla f(x)) + \frac{M}{2} ||\eta \nabla f(x)||_2^2 \\
\iff f(x^+) &amp;\leq f(x) +  \eta || \nabla f(x) ||_2^2 + \frac{M \eta^2}{2} ||\nabla f(x)||_2^2
\end{aligned}
$$
<br></p>
<p>But the RHS is a quadratic function in $\eta$, the step-size. So, the upper bound on the next iterate $f(x^+)$, and consequently also the next iterate itself, can be minimized w.r.t. $\eta$. Essentially, we trust the upper bound is a good quadratic approximation and choose its minimizer as the next iterate. Just like in NM we trust the quadratic estimate, and set its minimizer as the next iterate. But here, we require no second-order information about the function.</p>
<p>The non-NM view is this. We have a fixed $x$ and the quadratic upper bound at that $x$. Any next iterate will be smaller than the qudratic UB <em>at</em> that iterate. So we choose a step size that minimizes this UB. This guarantees $f(x^+) \leq$ min of UB which is the tightest guarantee we can get on $f(x^+)$ with the information at hand. So we, once again, do the locally optimal thing and choose that.</p>
<p>The best choice turns out to be $\eta = \frac{1}{M}$</p>
<p>FOR FUNCTIONS THAT ARE M SMOOTH M WORKS FOR EVERY POINT. WHEREAS WE ARE SHIT OUT OF LUCK IF SUCH AN M DOESN'T EXIST. THEN WE DON'T HAVE THIS UB. IT IS THEN THAT WE USE EITHER NM OR QUASI-NM.</p>
<p>||||</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="v-poghosyan/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-dark"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/optimization/applied%20mathematics/proofs/2022/03/03/Convex-Optimization-Algorithms-for-Unconstrained-Optimization-Gradient-Descent.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Personal blog about Machine Learning, Data Science, Mathematics, Software Engineering, and various other topics. Created by Vahram Poghosyan, © 2021 - Present.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/v-poghosyan" target="_blank" title="v-poghosyan"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/Vahram31680593" target="_blank" title="Vahram31680593"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
