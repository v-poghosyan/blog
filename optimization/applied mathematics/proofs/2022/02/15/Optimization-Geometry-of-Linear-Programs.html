<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Optimization - Linear Programs and LP Geometry | Vahram Poghosyan</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Optimization - Linear Programs and LP Geometry" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Linear Programs, Feasibility and Boundedness, Basic Feasible Solutions, and The Extreme Point Theorem" />
<meta property="og:description" content="Linear Programs, Feasibility and Boundedness, Basic Feasible Solutions, and The Extreme Point Theorem" />
<link rel="canonical" href="https://v-poghosyan.github.io/blog/optimization/applied%20mathematics/proofs/2022/02/15/Optimization-Geometry-of-Linear-Programs.html" />
<meta property="og:url" content="https://v-poghosyan.github.io/blog/optimization/applied%20mathematics/proofs/2022/02/15/Optimization-Geometry-of-Linear-Programs.html" />
<meta property="og:site_name" content="Vahram Poghosyan" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-02-15T00:00:00-06:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Optimization - Linear Programs and LP Geometry" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-02-15T00:00:00-06:00","datePublished":"2022-02-15T00:00:00-06:00","description":"Linear Programs, Feasibility and Boundedness, Basic Feasible Solutions, and The Extreme Point Theorem","headline":"Optimization - Linear Programs and LP Geometry","mainEntityOfPage":{"@type":"WebPage","@id":"https://v-poghosyan.github.io/blog/optimization/applied%20mathematics/proofs/2022/02/15/Optimization-Geometry-of-Linear-Programs.html"},"url":"https://v-poghosyan.github.io/blog/optimization/applied%20mathematics/proofs/2022/02/15/Optimization-Geometry-of-Linear-Programs.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://v-poghosyan.github.io/blog/feed.xml" title="Vahram Poghosyan" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-QB9Q6T3YNL"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-QB9Q6T3YNL');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Vahram Poghosyan</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Optimization - Linear Programs and LP Geometry</h1><p class="page-description">Linear Programs, Feasibility and Boundedness, Basic Feasible Solutions, and The Extreme Point Theorem</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-02-15T00:00:00-06:00" itemprop="datePublished">
        Feb 15, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      15 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#Optimization">Optimization</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#Applied Mathematics">Applied Mathematics</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#Proofs">Proofs</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/v-poghosyan/blog/tree/master/_notebooks/Optimization - Geometry of Linear Programs.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/v-poghosyan/blog/master?filepath=_notebooks%2FOptimization+-+Geometry+of+Linear+Programs.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/v-poghosyan/blog/blob/master/_notebooks/Optimization - Geometry of Linear Programs.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#Introduction">Introduction </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Applications">Applications </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Feasibility-and-Boundedness">Feasibility and Boundedness </a></li>
<li class="toc-entry toc-h1"><a href="#Converting-to-Standard-Form">Converting to Standard Form </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Introducing-Slack-Variables">Introducing Slack Variables </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Geometry-of-Linear-Programs">Geometry of Linear Programs </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Extreme-Points---Geometric-Definitions">Extreme Points - Geometric Definitions </a></li>
<li class="toc-entry toc-h2"><a href="#Extreme-Points---Algebraic-Definition">Extreme Points - Algebraic Definition </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Basic-Feasible-Solution">Basic Feasible Solution </a></li>
<li class="toc-entry toc-h3"><a href="#Matrix-Vector-Formulation-of-Basic-Feasible-Solutions">Matrix-Vector Formulation of Basic Feasible Solutions </a></li>
<li class="toc-entry toc-h3"><a href="#Basic-Feasible-Solutions-and-Extreme-Points-are-Equivalent">Basic Feasible Solutions and Extreme Points are Equivalent </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Proof">Proof </a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#The-Extreme-Point-Theorem">The Extreme Point Theorem </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Proof">Proof </a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Conclusion">Conclusion </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/Optimization - Geometry of Linear Programs.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Introduction">
<a class="anchor" href="#Introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction<a class="anchor-link" href="#Introduction"> </a>
</h1>
<p>A linear program is a convex optimization problem in $n$-dimensions with a linear objective and a polytope constraint. That is, its constraint set is an intersection of $n$-dimentsional linear inequalities (<em>halfspaces</em>) and linear equalities (<em>hyperplanes</em>).</p>
<p>In matrix form, it may be stated as</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$
\begin{cases}
min_x: c^Tx
\\
s.t.: \begin{aligned} &amp;A_1x \leq b_1
\\
&amp;A_2x \geq b_2
\\ 
&amp;A_3x = b_3
\end{aligned}
\end{cases}
$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>where $c \in \mathbb{R}^n$ is the <em>cost vector</em> of the objective function, $x \in \mathbb{R^n}$ is the <em>decision variable</em>, $A_1 \in \mathbb{R}^{m \times n}$, $b_1 \in \mathbb{R}^m$ and $A_2 \in \mathbb{R}^{p \times n}$, $b_2 \in \mathbb{R}^p$ together define the collection of linear inequality constraints, and $A_3 \in \mathbb{R}^{q \times n}$ and $b_3 \in \mathbb{R}^q$ define the collection of linear equality constraints.</p>
<p>As we will shortly prove, an LP in any form such as the one above can be converted into its <em>standard form</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$
\begin{cases}
min_x: c^Tx
\\
s.t.: \begin{aligned} &amp;Ax = b
\\ 
&amp;x \geq 0
\end{aligned}
\end{cases} \dagger
$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Applications">
<a class="anchor" href="#Applications" aria-hidden="true"><span class="octicon octicon-link"></span></a>Applications<a class="anchor-link" href="#Applications"> </a>
</h2>
<p>Linear programs are only a small subset of convex optimization problems but they're robust enough to model many real-life scenarios. For instance, even though they are continuous optimization problems, due to their geometry — namely the fact that optimal solutions to an LP may occur only at the extreme points of the constraint set — they have a strong combinatorial flavor. This is why LP's are highly successful at modeling problems that are inherently combinatorial — problems of scheduling, finding the shortest path, modeling a <a href="https://v-poghosyan.github.io/blog/optimization/combinatorics/applied%20mathematics/2022/02/09/Optimization-Robust-Linear-Programs-Modelling-Discrete-Failures.html">discrete failures scenario</a>, etc.</p>
<p>The reason LP's are of special interest in the study of optimization is due to the availability of fast algorithms that solve them. So, if a convex optimization problem happens to also be an LP, we can solve it much faster.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Feasibility-and-Boundedness">
<a class="anchor" href="#Feasibility-and-Boundedness" aria-hidden="true"><span class="octicon octicon-link"></span></a>Feasibility and Boundedness<a class="anchor-link" href="#Feasibility-and-Boundedness"> </a>
</h1>
<p>There are two ways in which LP's may fail to have an optimal solution, by either being <em>infeasible</em> or <em>unbounded</em>. Both of these cases are typically uninteresting in practice however they give important theoretical results. It's also useful to check whether or not a given LP is feasible and bounded before attempting to optimize.</p>
<p>Infeasible LP's are those LP's that have an empty constraint set, whereas unbounded LP's have open constraint sets. However, it's important to understand that an LP may have an open constraint set without being unbounded.</p>
<p>Consider the two examples below</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\begin{cases}
min_{x_1}: x_1
\\
s.t.: x_1 \leq 4
\end{cases} \tag{1}
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\begin{cases}
min_{x_1}: x_1
\\
s.t.: x_1 \geq 4
\end{cases} \tag{2}
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The first problem is unbounded, since $x_1$ can be taken arbitrarily small. However, the second problem is bounded despite having an open constraint set. The optimal value of $(2)$ is $x_1 = 4$.</p>
<p>Thus, an LP is said to be unbounded not when its constraint polytope is open, but when it's feasible and has no optimal solution.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Converting-to-Standard-Form">
<a class="anchor" href="#Converting-to-Standard-Form" aria-hidden="true"><span class="octicon octicon-link"></span></a>Converting to Standard Form<a class="anchor-link" href="#Converting-to-Standard-Form"> </a>
</h1>
<p>Given any starting point, an LP can be written in standard form $\dagger$. This is useful for standardization of the problem from an algorithmic perspective, and it's what the <a href="https://en.wikipedia.org/wiki/Simplex_algorithm">Simplex algorithm</a> relies on to solve LP's.</p>
<p>In the most general case an LP can be stated with inequality constraints going in both directions and equality constraints as follows</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$
\begin{cases}
min_x: c^Tx
\\
s.t.: \begin{aligned} &amp;A_1x \leq  b_1
\\
&amp;A_2x \geq  b_2
\\ 
&amp;A_3x = b_3
\end{aligned}
\end{cases}
$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>But the inequality constraints can always be combined into $Ax \leq b$ for $A = [A_1, A_2]$ 
and $b = [b_1, -b_2]^T$ and relabeled as $A_1$ and $b_1$.</p>
<p>So there's no qualitative difference between having two types of inequalities versus just one. Simply concatenate and relabel the matrices to get</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$
\begin{cases}
min_x: c^Tx
\\
s.t.: \begin{aligned} &amp;A_1x \leq  b_1
\\
&amp;A_2x = b_2
\end{aligned}
\end{cases}
$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The real challenge lies in converting the inequality constraints $A_1x \leq b_1$ into equality constraints $A_1x = b_1$.</p>
<h2 id="Introducing-Slack-Variables">
<a class="anchor" href="#Introducing-Slack-Variables" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introducing Slack Variables<a class="anchor-link" href="#Introducing-Slack-Variables"> </a>
</h2>
<p>The inequality constraint $A_1x \leq b_1$ has <em>slack</em>. Formally, we can define vector $s \geq 0$ (component-wise), that bridges the gap between $A_1x$ and $b_1$, that is s.t. $A_1x + s = b_1$.</p>
<p>Since this introduces new variables, we have to represent those in the objective and the equality constraints in a way that doesn't affect the optimization outcome.</p>
<p>The LP becomes</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$
\begin{cases}
min_x: c^Tx + \mathbf{0}^Ts
\\
s.t.: \begin{aligned} &amp;A_1x + s = b_1
\\ 
&amp;A_2x + 0s = b_2
\\
&amp;s \geq 0
\end{aligned}
\end{cases}
$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This LP is equivalent to the one before. Namely, if the previous optimizer was $x^*$, the optimizer in the new LP is the concatenation $[x^*, b_1 - A_1x]$ which gives the same optimal value in the objective function.</p>
<p>This is almost in standard form, an LP with only equality constraints, and non-negativity constraints. However, the decision variable of this LP is the concatenation $[x,s]^T$, whereas the non-negativity applies to $s$ alone.</p>
<p>The next step is to decompose $x$ as $x = x^+ - x^-$ where $x^+,x^- \geq 0$ respectively contain only the positive and only the negative entries of $x$. That is, $x^+$, and $x^-$ have entries $x_i^+ = max\{0, x_i\}$ and $x_i^- = -min\{0, x_i\}$.</p>
<p>With this substitution we get</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$
\begin{cases}
min_x: c^Tx^+ - c^Tx^- + \mathbf{0}^Ts
\\
s.t.: \begin{aligned} &amp;A_1x^+ - A_1x^- + s = b_1
\\ 
&amp;A_2x^+ - A_2x^- + 0s = b_2
\\
&amp;x^+, x^-, s \geq 0
\end{aligned}
\end{cases}
$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Which is an LP in standard form $\dagger$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Geometry-of-Linear-Programs">
<a class="anchor" href="#Geometry-of-Linear-Programs" aria-hidden="true"><span class="octicon octicon-link"></span></a>Geometry of Linear Programs<a class="anchor-link" href="#Geometry-of-Linear-Programs"> </a>
</h1>
<p>Take a simple feasible, bounded LP in two dimensions that has a unique solution, draw its polygonal constraint set. Then draw the level sets of the objective function noting that the direction of steepest change (the positive or negative gradient) is perpendicular to the level sets. The conclusion is almost immediate — the unique optimal solution occurs at a vertex (i.e. an <em>extreme point</em>) of the polygonal constraint set.</p>
<p>To formalize this, we need to introduce a few definitions and prove a theorem called The Extreme Point Theorem which can be found towards the end of this post.</p>
<h2 id="Extreme-Points---Geometric-Definitions">
<a class="anchor" href="#Extreme-Points---Geometric-Definitions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Extreme Points - Geometric Definitions<a class="anchor-link" href="#Extreme-Points---Geometric-Definitions"> </a>
</h2>
<p>First, let's give a couple of geometric definitions of an extreme point.</p>
<blockquote>
<p>Definition 1:  A point $x$ is an <strong>extreme point</strong> of a polytope $P$ if it is <em>not</em> the convex combination of any other two points in the polytope.<br></p>
</blockquote>
<p>That is, if $\exists y,z \in P$ and $\lambda \in [0,1]$ s.t. $x = \lambda y + (1- \lambda)z$ then $x$ is <strong>not</strong> an extreme point of $P$.</p>
<blockquote>
<p>Definition 2:  A point $x$ is an <strong>extreme point</strong> of a polytope $P$ if it is the <em>unique</em> optimum for some cost vector $c$.<br></p>
</blockquote>
<p>That is, if $\exists c \in \mathbb{R}^n$ s.t. $c^Tx &lt; c^Ty \ \ \forall y \in P$ then $x$ is an extreme point.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Extreme-Points---Algebraic-Definition">
<a class="anchor" href="#Extreme-Points---Algebraic-Definition" aria-hidden="true"><span class="octicon octicon-link"></span></a>Extreme Points - Algebraic Definition<a class="anchor-link" href="#Extreme-Points---Algebraic-Definition"> </a>
</h2>
<p>It's useful to define an extreme point algebraically. To that end, let's define the concept of a <em>basic feasible solution (BFS)</em>.</p>
<p>Suppose we have the polytope $\{x : Ax \leq b, Dx = f\}$.</p>
<blockquote>
<p>Definition:  An <strong>active constraint at $x$</strong> is a constraint that's satisfied through strict equality.<br></p>
</blockquote>
<p>That is, the $i$-th constraint is said to be active at x if $a_i^Tx = b_i$.</p>
<p>This can be thought of as $x$ being on the edge of the halfspace defined by $a_i^Tx \leq b_i$.</p>
<p>We can also define the <em>active set</em> at $x$ as the set of all active constraints at $x$.</p>
<p>So, the active set at $x$ is $\mathcal{A}_x = \{ a_i : a_i^Tx = b_i \} \cup \{ d_i : d_i^Tx = f_i \}$, where $\{ d_i : d_i^Tx = f_i \}$ is included for completion.</p>
<h3 id="Basic-Feasible-Solution">
<a class="anchor" href="#Basic-Feasible-Solution" aria-hidden="true"><span class="octicon octicon-link"></span></a>Basic Feasible Solution<a class="anchor-link" href="#Basic-Feasible-Solution"> </a>
</h3>
<p>We are now ready to define what it means for a point $x$ to be a basic feasible solution of a linear program.</p>
<blockquote>
<p>Definition:  The point $x$ is a <strong>basic feasible solution (BFS)</strong> of the linear program if its active set $\mathcal{A}_x$ contains exactly $n$ linearly independent vectors where $n$ is the  dimension of $x$.<br></p>
</blockquote>
<p>Let's ponder the BFS definition for a minute.</p>
<p>Imagine a closed polytope in 2D. Each of its vertices are defined by, at least, two intersecting lines. It's possible that a vertex is the result of the intersection of three or more lines, but deleting all but two of those lines will still retain the vertex. In other words, two linearly independent (i.e. non-parallel) constraints define an extreme point in 2D.</p>
<p>The BFS definition is simply a generalization of this insight to $n$-dimensions.</p>
<p>As we will prove shortly, BFS and extreme point are synonymous. In fact, the following are equivalent:</p>
<ul>
<li>$x$ is an extreme point by <em>Definition 1</em>. </li>
<li>$x$ is an extreme point by <em>Definition 2</em>.</li>
<li>$x$ is a basic feasible solution.</li>
</ul>
<h3 id="Matrix-Vector-Formulation-of-Basic-Feasible-Solutions">
<a class="anchor" href="#Matrix-Vector-Formulation-of-Basic-Feasible-Solutions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Matrix-Vector Formulation of Basic Feasible Solutions<a class="anchor-link" href="#Matrix-Vector-Formulation-of-Basic-Feasible-Solutions"> </a>
</h3>
<p>Taking as our starting point an LP in standard form $\dagger$ we can characterize basic feasible solutions in matrix-vector form.</p>
<p>Take the standard constraint set $\Omega = \{ Ax = b, x \geq 0 \}$ and let's make a few simplifying assumptions.</p>
<ol>
<li>$A$ is $m \times n$ with $m \leq n$.</li>
<li>$A$ is full-rank</li>
<li>$b \geq 0$</li>
<li>$A$ has form $A = [B,D]$ where $B$ is an $m \times m$ full-rank matrix and $D$ is the rest of $A$.</li>
</ol>
<p>Some of these assumptions impose restrictions on $\Omega$, whereas others are without loss of generality.</p>
<p>Assumption 1 is simply there to make the problem interesting. Were $n &gt; m$, the system of equalities would be over-determined and the constraint set would either be empty or contain a single point, which itself would be the optimum. It is, therefore an assumption which is <em>not</em> done without loss of generality.</p>
<p>Assumption 2 is equivalent to saying $rank(A) = m$. That is to say, all $m$ rows of $A$, as well as $m$ of the $n$ columns of $A$, are linearly independent. This assumption is also <em>not</em> done without loss of generality. Having less linearly independent rows corresponds to having less non-redundant constraints which clearly affects the constraint set $\Omega$.</p>
<p>Assumption 3 is done W.L.O.G. since the signs of $A$'s row entries can always be flipped.</p>
<p>Assumption 4 is also done W.L.O.G. because if $A$ contains a full-rank $m \times m$ submatrix per Assumption 2, then $A = [B,D]$ is a re-ordering of $A$ which adds no further restrictions on $\Omega$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For $\Omega$ that satisfies Assumptions 1-4, the basic feasible solutions can be reformulated as follows.</p>
<blockquote>
<p>Definition:  Let $x_B$ be such that. $Bx_B = b$. Then the concatenation $x = [x_B, 0]^T$ is a solution to $Ax = b$. Such solutions are called <strong>feasible solutions</strong>. Furthermore, if $x_B \geq 0$, such solutions are called <strong>basic ferasible solutions</strong>.<br></p>
</blockquote>
<p>Note that, for the case we're in, this is consistent with the earlier definition of a BFS.</p>
<p>Let $x$ be a BFS according to this definition. $Ax = b$ poses a set of $m$ linearly independent constraints since $rank(A) = m$, whereas $x \geq 0$ poses a set of $n$. But $x = [x_B, 0]^T$ is a vector at which all $m$ of the equality constraints $Ax = b$ are active, and $n-m$ of the inequality constraints $x \geq 0$ are also active. So in total $n$ linearly independent constraints are active at a BFS, which is consistent with the earlier definition.</p>
<h3 id="Basic-Feasible-Solutions-and-Extreme-Points-are-Equivalent">
<a class="anchor" href="#Basic-Feasible-Solutions-and-Extreme-Points-are-Equivalent" aria-hidden="true"><span class="octicon octicon-link"></span></a>Basic Feasible Solutions and Extreme Points are Equivalent<a class="anchor-link" href="#Basic-Feasible-Solutions-and-Extreme-Points-are-Equivalent"> </a>
</h3>
<p>To formally prove that basic feasible solutions are extreme points in the geometric sense, consider the following theorem and its proof.</p>
<blockquote>
<p>Theorem:  The point $x$ is an extreme point of $\Omega = \{ Ax =b, x \geq 0 \}$ if and only if it is a basic feasible solution.<br></p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Proof">
<a class="anchor" href="#Proof" aria-hidden="true"><span class="octicon octicon-link"></span></a>Proof<a class="anchor-link" href="#Proof"> </a>
</h4>
<p><strong>Sufficiency: $\implies$</strong></p>
<p>Let $x$ be an extreme point of $\Omega$. Since it's in $\Omega$, $x \geq 0$ and $Ax = b$.</p>
<p>Equivalently, $\sum_{i=1}^n x_ia_i = b$ where the $a_i$'s are the column vectors of $A$.</p>
<p>Note that $x$ <em>must</em> contain zero entries, since it takes $n$ linearly independent active constraints to be an extreme point and only $m$ come from the equality constraints $Ax = b$.</p>
<p>By Assumption 1, $m$ of $A$'s columns are linearly independent. We'd like to claim that these $m$ are exactly those corresponding to the non-zero $x_i$ entries.</p>
<p>If this claim turns out to be true, then the full-rank $m \times m$ submatrix $B$ will contain exactly those $m$ columns. And $x = [x_B, 0]^T$, where $x_B$ are the non-zero entries of $x$, would be a BFS. $\ast$</p>
<p>So, let's prove the linear independence claim using a contradiction argument.</p>
<p>Without loss of generality, through rearrangement, let the first $m$ elements be the nonzero entries. That is, $x_1, ..., x_m &gt; 0$, and $x_{m+1}, ... ,x_n = 0$.</p>
<p>Then $\sum_{i=1}^n x_ia_i = \sum_{i=1}^m x_ia_i = b$.</p>
<p>Towards contradiction, assume $a_1, ..., a_m$ are linearly dependent. Then $\exists y_1, ..., y_m \in \mathbb{R}$ not all zero s.t. $y_1a_1 + ... + y_ma_m = 0$</p>
<p>Take $\epsilon &gt; 0$ to be very small. Small enough so that $x_i \pm \epsilon y_i &gt; 0 \ \ \forall i = 1,...,m$.</p>
<p>Define two points as</p>
<p>$z^1 = [x_1 - \epsilon y_1, ..., x_p - \epsilon y_p, 0, ..., 0]^T$ and, 
$z^2 = [x_1 + \epsilon y_1, ..., x_p + \epsilon y_p, 0, ..., 0]^T$.</p>
<p>These points clearly satisfy $z_1,z_2 \geq 0$, so they they satisfy one of $\Omega$'s constraints.</p>
<p>Furthermore,</p>
<p>$Az^1 = \sum_{i=1}^m z^1_ia_i = \sum_{i=1}^m x_ia_i - \epsilon \sum_{i=1}^m y_ia_i = b$ since $\sum_{i=1}^m y_ia_i = 0$.</p>
<p>and similarly $Az^2 = b$.</p>
<p>So, $z^1$, and $z^2$ are indeed in $\Omega$.</p>
<p>But note that $x = \frac{z^1 + z^2}{2}$ is a convex combination of two points in $\Omega$, which contradicts the assumption that it's an extreme point.</p>
<p>Hence, $a_1,...,a_m$ must be linearly independent. This concludes the proof by $\ast$.</p>
<p><strong>Necessity: $\impliedby$</strong></p>
<p>Suppose $x$ is a BFS and assume, towards contradiction, that it's <em>not</em> and extreme point of $\Omega$.</p>
<p>Then $\exists y,z \in \Omega$ with $y \ne z$ s.t. $x = \alpha y + (1- \alpha) z$ for some $\alpha \in (0,1)$.</p>
<p>But since $y,z \in \Omega$ they satisfy $Ay = Az = b$, so $Ay - Az = A(y - z) 0$.</p>
<p>That is $(y_1 - z_1)a_1 + ... + (y_m - z_m)a_m = 0$.</p>
<p>But since $y \ne z$, not all $(y_i - z_i) = 0$. So, $a_1,..., a_m$ are linearly dependent. This contradicts the assumption that $x$ was a BFS.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Extreme-Point-Theorem">
<a class="anchor" href="#The-Extreme-Point-Theorem" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Extreme Point Theorem<a class="anchor-link" href="#The-Extreme-Point-Theorem"> </a>
</h2>
<p>Why devote so much time defining extreme points geometrically, and then again algebraically? As hinted earlier and as shall be proved shortly, optima of linear programs can <em>only</em> occur at extreme points. This is the reason LP's are a class of easy convex optimization problems — the search space for their optima can be reduced to a finite number of extreme points.</p>
<blockquote>
<p>The Extreme Point Theorem:  If a linear program&gt;</p>
<ul>
<li>has a finite optimum, and </li>
<li>its constraint polytope has at least one extreme point,</li>
</ul>
<p>then there is an extreme point which is optimal.
<br></p>
</blockquote>
<p>So, if we want to solve linear programs we need only consider the extreme points.</p>
<p>Let's prove the theorem through induction on the dimension.</p>
<h3 id="Proof">
<a class="anchor" href="#Proof" aria-hidden="true"><span class="octicon octicon-link"></span></a>Proof<a class="anchor-link" href="#Proof"> </a>
</h3>
<p>Take the following general LP and assume it has a finite optimum. Assume also that its constraint polytope has, at least, one extreme point.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$
\begin{cases}
min_{x}: c^Tx
\\
s.t.: x \in P
\end{cases}
$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Assume the theorem is true for this LP with an $(n-1)$-dimensional constraint polytope. The objective is to show that it's also true for the same LP with an $n$-dimensional constraint polytope.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let $v$ be the optimal value of the LP.</p>
<p>Let $Q = P \cap \{ x : c^Tx = v \}$ be the intersection of the constraint polytope with the level set of the objective function at the optimal value.</p>
<p>Since $Q$ is the intersection of an $n$-dimensional polytope $P$ with an additional linear constraint (a hyperplane), it is $(n-1)$-dimensional.</p>
<p>By the inductive hypothesis, there is an extreme point $x^* \in Q$ that's optimal for the LP.</p>
<p>By a contradiction argument, $x^*$ is also an extreme point in $P$.</p>
<p>Suppose it is <em>not</em> an extreme point in $P$. Then by <em>Definition 1</em> of extreme point, $x^*$ is a convex combination of two points in $P$. That is, $\exists y,z \in P$ s.t. $\lambda y + (1- \lambda)z = x^*$ for some $\lambda \in [0,1]$.</p>
<p>But then $\lambda c^Ty + (1- \lambda)c^Tz = c^Tx^* = v$, since $x^*$ is optimal. But the right hand side is a convex combination of scalars, so $c^Ty = c^Tz = v$. This means $y,z \in Q$, which contradicts the fact that $x^*$ is an extreme point in $Q$.</p>
<p>Hence, $x^*$ must be an extreme point in $P$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Conclusion">
<a class="anchor" href="#Conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion<a class="anchor-link" href="#Conclusion"> </a>
</h1>
<p>Linear programs are a sub-class of convex optimization problems for which the search space can be reduced to a finite set of basic feasible solutions or extreme points. This lends LP's to be solvable using a number of fast, iterative algorithms.</p>

</div>
</div>
</div>
</div>



  </div><a class="u-url" href="/blog/optimization/applied%20mathematics/proofs/2022/02/15/Optimization-Geometry-of-Linear-Programs.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Personal blog about Machine Learning, Data Science, Mathematics, Software Engineering, and various other topics. Created by Vahram Poghosyan, © 2021 - Present.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/v-poghosyan" target="_blank" title="v-poghosyan"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/Vahram31680593" target="_blank" title="Vahram31680593"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
