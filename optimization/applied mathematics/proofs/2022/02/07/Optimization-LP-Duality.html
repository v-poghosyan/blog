<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Optimization - Duality | Vahram Poghosyan</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Optimization - Duality" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Lagrangian Duality, Weak and Strong Duality, Complementary Slackness, Farkas’ Lemma, Separation Arguments and Theorems of the Alternative" />
<meta property="og:description" content="Lagrangian Duality, Weak and Strong Duality, Complementary Slackness, Farkas’ Lemma, Separation Arguments and Theorems of the Alternative" />
<link rel="canonical" href="https://v-poghosyan.github.io/blog/optimization/applied%20mathematics/proofs/2022/02/07/Optimization-LP-Duality.html" />
<meta property="og:url" content="https://v-poghosyan.github.io/blog/optimization/applied%20mathematics/proofs/2022/02/07/Optimization-LP-Duality.html" />
<meta property="og:site_name" content="Vahram Poghosyan" />
<meta property="og:image" content="https://v-poghosyan.github.io/blog/images/lp-duality.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-02-07T00:00:00-06:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://v-poghosyan.github.io/blog/images/lp-duality.png" />
<meta property="twitter:title" content="Optimization - Duality" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-02-07T00:00:00-06:00","datePublished":"2022-02-07T00:00:00-06:00","description":"Lagrangian Duality, Weak and Strong Duality, Complementary Slackness, Farkas’ Lemma, Separation Arguments and Theorems of the Alternative","headline":"Optimization - Duality","image":"https://v-poghosyan.github.io/blog/images/lp-duality.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://v-poghosyan.github.io/blog/optimization/applied%20mathematics/proofs/2022/02/07/Optimization-LP-Duality.html"},"url":"https://v-poghosyan.github.io/blog/optimization/applied%20mathematics/proofs/2022/02/07/Optimization-LP-Duality.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://v-poghosyan.github.io/blog/feed.xml" title="Vahram Poghosyan" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-QB9Q6T3YNL"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-QB9Q6T3YNL');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Vahram Poghosyan</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Optimization -  Duality</h1><p class="page-description">Lagrangian Duality, Weak and Strong Duality, Complementary Slackness, Farkas' Lemma, Separation Arguments and Theorems of the Alternative</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-02-07T00:00:00-06:00" itemprop="datePublished">
        Feb 7, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      37 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#Optimization">Optimization</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#Applied Mathematics">Applied Mathematics</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#Proofs">Proofs</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/v-poghosyan/blog/tree/master/_notebooks/2022-02-07-Optimization-LP-Duality.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/v-poghosyan/blog/master?filepath=_notebooks%2F2022-02-07-Optimization-LP-Duality.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/v-poghosyan/blog/blob/master/_notebooks/2022-02-07-Optimization-LP-Duality.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#Introduction">Introduction </a></li>
<li class="toc-entry toc-h1"><a href="#Deriving-the-Dual-of-a-Constrained-Problem">Deriving the Dual of a Constrained Problem </a>
<ul>
<li class="toc-entry toc-h2"><a href="#The-Lagrangian,-Dual-Variables,-and-the-Dual-Function">The Lagrangian, Dual Variables, and the Dual Function </a></li>
<li class="toc-entry toc-h2"><a href="#A-Lagrangian-Lower-Bound-on-the-Optimal">A Lagrangian Lower Bound on the Optimal </a></li>
<li class="toc-entry toc-h2"><a href="#The-Lagrange-Dual-Problem">The Lagrange Dual Problem </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Weak-Duality">Weak Duality </a>
<ul>
<li class="toc-entry toc-h2"><a href="#The-Max-Min-Characterization">The Max-Min Characterization </a></li>
<li class="toc-entry toc-h2"><a href="#Max-Min-Inequality-and-its-Interpretations">Max-Min Inequality and its Interpretations </a>
<ul>
<li class="toc-entry toc-h3"><a href="#The-Max-Min-Inequality">The Max-Min Inequality </a></li>
<li class="toc-entry toc-h3"><a href="#Game-Theoretic-Interpretation">Game-Theoretic Interpretation </a></li>
<li class="toc-entry toc-h3"><a href="#Price-or-Tax-Interpretation">Price or Tax Interpretation </a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Strong-Duality">Strong Duality </a>
<ul>
<li class="toc-entry toc-h2"><a href="#An-Easier-Dual-Problem">An Easier Dual Problem </a></li>
<li class="toc-entry toc-h2"><a href="#Slater's-Condition---Sufficient-Condition-for-Strong-Duality">Slater&#39;s Condition - Sufficient Condition for Strong Duality </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Geometric-Intuition-Behind-Slater's-Condition">Geometric Intuition Behind Slater&#39;s Condition </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Complementary-Slackness---A-Consequence-of-Strong-Duality">Complementary Slackness - A Consequence of Strong Duality </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Proof-of-Complementary-Slackness">Proof of Complementary Slackness </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Optimality-Conditions">Optimality Conditions </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Karush-Kuhn-Tucker-(KKT)-Conditions">Karush-Kuhn-Tucker (KKT) Conditions </a></li>
<li class="toc-entry toc-h3"><a href="#Motivating-the-KKT-Conditions">Motivating the KKT Conditions </a></li>
<li class="toc-entry toc-h3"><a href="#KKT-as-a-Generalization-of-Unconstrained-Optimization">KKT as a Generalization of Unconstrained Optimization </a></li>
<li class="toc-entry toc-h3"><a href="#Stationarity-Condition---Geometric-Perspective">Stationarity Condition - Geometric Perspective </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Saddle-Point-Interpretation">Saddle Point Interpretation </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Max-Min-Equality-at-Saddle-Points">Max-Min Equality at Saddle Points </a></li>
<li class="toc-entry toc-h3"><a href="#Proof-of-Saddle-Point-Theorem">Proof of Saddle Point Theorem </a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#LINEAR-PROGRAMS">LINEAR PROGRAMS </a></li>
<li class="toc-entry toc-h1"><a href="#Weak-Duality-in-Linear-Programs">Weak Duality in Linear Programs </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Proof-of-Weak-Duality">Proof of Weak Duality </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Strong-Duality">Strong Duality </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Farkas'-Lemma">Farkas&#39; Lemma </a></li>
<li class="toc-entry toc-h2"><a href="#Proof-of-Strong-Duality-in-LP's">Proof of Strong Duality in LP&#39;s </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Theorems-of-the-Alternative">Theorems of the Alternative </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Example-of-a-Theorem-of-the-Alternative">Example of a Theorem of the Alternative </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Using-a-Separation-Argument">Using a Separation Argument </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Proof">Proof </a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#Using-Strong-Duality">Using Strong Duality </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Proof">Proof </a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Complementary-Slackness">Complementary Slackness </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Proof-of-Complementary-Slackness">Proof of Complementary Slackness </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-02-07-Optimization-LP-Duality.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Introduction">
<a class="anchor" href="#Introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction<a class="anchor-link" href="#Introduction"> </a>
</h1>
<p>Every linear program, and every optimization problem in general, has a closely related problem called its dual which can be colloquially thought of as its evil twin. The primal and the dual represent two different perspectives on the same problem.</p>
<p>In the most general case, if the primal is a minimization problem, its  dual is a maximization problem. In the case of constrained optimization, if the primal is minimization in $n$ variables and $m$ constraints, its dual is a maximization in $m$ variables and $n$ constraints.</p>
<p>Furthermore, any value attained by the dual problem is a lower bound of all the values attained by the primal and, in particular, the primal optimal value. This property, called <em>Weak Duality</em>, is at the core of duality. Deriving a dual that obtains, at the very least, a useful lower bound to the primal optimal value is one of the nascent ideas behind <em>Duality Theory</em>.</p>
<p>In the case of problems which exhibit <em>Strong Duality</em>, such as linear programs and most convex optimization problems, the primal and the dual optima are strictly equal. That is, solving the dual guarantees that we've also solved the primal. Furthermore, since taking the dual of the dual gives back the primal, this relationship is true in the converse — if we've solved the primal then we've also solved its dual.</p>
<p>This is what makes Duality Theory useful in practice. Having a related, possibly easier, optimization problem gives applied scientists a huge computational advantage. However, even if the dual does not turn out to be easier to solve and/or its optimal value disagrees with that of the primal, we still stand to elucidate the structure of the primal problem and/or obtain a useful lower bound to its optimal.</p>
<p>In this post, we will examine the nature of the relationship between the primal and its dual, and we will list the possible primal-dual outcomes. In doing so, we will look at duality in constrained optimization problems in general, and then duality in linear programs specifically (<em>LP Duality)</em>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Deriving-the-Dual-of-a-Constrained-Problem">
<a class="anchor" href="#Deriving-the-Dual-of-a-Constrained-Problem" aria-hidden="true"><span class="octicon octicon-link"></span></a>Deriving the Dual of a Constrained Problem<a class="anchor-link" href="#Deriving-the-Dual-of-a-Constrained-Problem"> </a>
</h1>
<p>At first, we focus our attention on deriving the dual problem of a constrained optimization problem. For problems of this sort, duality comes from the <a href="https://en.wikipedia.org/wiki/Lagrangian_relaxation">Lagrangian relaxation</a> which augments the constrained problem by turning it into an unconstrained problem that, nevertheless, respects the constraints of the original. So, in a sense, it is the constraints of a problem that give rise to its dual...</p>
<p>However, as we shall see later, certain types of unconstrained problems also have duals which arise from the <a href="https://en.wikipedia.org/wiki/Convex_conjugate">Fenchel-Legendre Transform</a>.</p>
<p>Take the most general form of constrained optimization problem with $m$ inequality and $n$ equality constraints and assume nothing, as of yet, about its convexity. To make the discussion interesting, assume the problem is non-trivial (i.e. its constraint set is non-empty and contains more than one feasible point), and also that it's bounded with a finite optimum $f_0(x^*) = p^*$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$
\begin{cases}
\min_x: f_0(x)
\\
s.t.: \begin{aligned} &amp;f_i(x) \leq 0 \ \ i = 1, ...,m
\\ 
&amp;h_i(x) = 0 \ \ i = 1, ... ,p
\end{aligned}
\end{cases}
$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The idea is to penalize infeasible choices of $x$ using functions of $x$ that express our <em>displeasure</em> for certain choices.</p>
<p>At first we use an <em>infinitely-hard</em> penalty by introducing the indicator functions $\mathbb{1}_-$ and $\mathbb{1}_0$ which are defined as follows:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\mathbb{1}_-(u) = 
\begin{cases}
\begin{aligned} 
&amp;0  &amp;\textrm{if} \ u \leq 0
\\
&amp;\infty  &amp;\textrm{if} \ u &gt; 0
\end{aligned}
\end{cases}$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\mathbb{1}_0(u) = 
\begin{cases}
\begin{aligned} 
&amp;0  &amp;\textrm{if} \ u = 0
\\
&amp;\infty  &amp;\textrm{if} \ u \ne 0
\end{aligned}
\end{cases}$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then the equivalent unconstrained problem is:</p>
<p>$\min_x: \mathcal{J}(x)$</p>
<p>where $\mathcal{J}(x) = f_0(x) + \sum_{i=1}^m \mathbb{1}_-(f_i(x)) + \sum_{i=1}^p \mathbb{1}_0(h_i(x))$</p>
<p>This objective can also be expressed as:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\mathcal{J}(x) = \begin{cases}\begin{aligned} 
&amp;f_0(x) \ \ \textrm{if $x$ is feasible}
\\
&amp;\infty \ \ \textrm{otherwise}
\end{aligned}\end{cases}$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If $x$ is chosen s.t any of the constraints is broken the minimization incurs an infinitely positive penalty. Therefore, such an $x$ will never be selected over a solution that gives a finite value of $f_0(x)$. Moreover, the optimal solution will be $x^*$ s.t. $f_0(x^*)$ is minimal. That is $\min_x \mathcal{J}(x) = f_0(x^*) = p^*$.</p>
<p>And, crucially, since $x^*$ is feasible for the original problem $J(x^*) = f_0(x^*)$ by definition. So a minimizer $x^*$ for the original problem is also a minimizer of the unconstrained problem with the infinitely-hard penalty.</p>
<p>This shows that the two problems are equivalent, and hence that it suffices to optimize $\mathcal{J}(x)$ instead of the original.</p>
<p>As we know, unconstrained problems can be locally optimized simply by identifying their stationary points using a first-order necessary condition. Once the stationary points are identified, we can evaluate the objective function at each and discern the optimizer.</p>
<p>The first-order necessary optimality condition concerns the directional derivative of the objective function. Namely, it attests that the directional derivative at a local optimizer should be zero in all feasible directions. But <em>all points</em> of an unconstrained problem are, effectively, interior points. Thus, all directions are feasible. So the first-order necessary condition amounts to the gradient being zero at a local optimizer.</p>
<p>However, the infinitely-hard penalty functions are discontinuous and, therefore also, non-differentiable. That is $\nabla_x \mathcal{J}(x)$ does not exist. To sidestep this difficulty we use linear relaxations instead of $\mathbb{1}_-$ and $\mathbb{1}_0$.</p>
<h2 id="The-Lagrangian,-Dual-Variables,-and-the-Dual-Function">
<a class="anchor" href="#The-Lagrangian,-Dual-Variables,-and-the-Dual-Function" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Lagrangian, Dual Variables, and the Dual Function<a class="anchor-link" href="#The-Lagrangian,-Dual-Variables,-and-the-Dual-Function"> </a>
</h2>
<p>The Lagrangian linear relaxation, sometimes simply referred to as the <em>Lagrangian</em>, is:</p>
<p>
$$\mathcal{L}(x,\lambda,\mu) = f_0(x) + \sum_{i=1}^m \lambda_i f_i(x) + \sum_{i=1}^p \mu_i h_i(x) \ \ \textrm{where} \ \lambda \geq 0$$
</p>
<p>We call the $\lambda_i$'s the <em>Lagrange multipliers</em> corresponding to the inequality constraints, and the $\mu_i$'s the <em>Lagrange multipliers</em> corresponding to the equality constraints. The vectors $\lambda$ and $\mu$ are called the <em>Lagrange multiplier vectors</em> or, for reasons that will soon become apparent, the <em>dual variables</em>. 
</p>
<div class="flash">
    <svg class="octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>In many sources, the Lagrangian is simply stated as $\mathcal{L}(x,\lambda) = f_0(x) + \sum_{i=1}^n \lambda_i f_i(x)$. Indeed, by breaking down the equality constraints $h_i(x) = 0$ into $h_i(x) \leq 0$ and $-h_i(x) \leq 0$, we can transform a problem with equality constraints into one with only inequality constraints. So, the latter representation of the Lagrangian is still general enough to account for equality constraints.
</div>
<br>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="A-Lagrangian-Lower-Bound-on-the-Optimal">
<a class="anchor" href="#A-Lagrangian-Lower-Bound-on-the-Optimal" aria-hidden="true"><span class="octicon octicon-link"></span></a>A Lagrangian Lower Bound on the Optimal<a class="anchor-link" href="#A-Lagrangian-Lower-Bound-on-the-Optimal"> </a>
</h2>
<p>Not only does the Lagrangian augment a constrained problem into an unconstrained problem that's solvable by using the method of unconstrained optimization, it also gives us the <em>dual problem</em>.</p>
<p>The first thing to note about the Lagrangian is that $\lambda \geq 0$ is necessary. This is because, in the event that an inequality constraint is violated, say $f_i(x) &gt; 0$ for some $i$, the corresponding $\lambda_i$ must be non-negative in order to apply a positive penalty for the violation. This extends to all the entries of $\lambda$, resulting in the $\lambda \geq 0$ coordinate-wise condition.</p>
<p>On the other hand, $\mu$ is free to assume any value since the equality constraints can be violated in either direction and both scenarios must be penalized.</p>
<p>The second thing to note about the $\mathcal{L}$ is that, even though we apply a positive penalty that scales linearly in the severity of the violation, this penalty is <em>still</em> not as severe as the infinite penalty we were applying in $\mathcal{J}$. Also, in the Lagrangian, we actually <em>reward</em> feasible choices of $x$ that have margin. That is, in the event that $f_i(x) &lt; 0$ strictly for some $i$, $\lambda_if_i(x)$ is a non-positive reward for the minimization problem.</p>
<p>All of this is to say that the Lagrangian is a lower bound of the unconstrained problem with the infinitely-hard penalty. That is:</p>
$$\forall x, \lambda \geq 0, \mu, \ \ \mathcal{L}(x,\lambda,\mu) \leq J(x) \tag{1}$$<p></p>
<p>This fact is also true by noticing that $\lambda_i f_i(x) \leq \mathbb{1}_-(f_i(x))$ and $\mu_i h_i(x) \leq \mathbb{1}_0(h_i(x))$ for all $i$.</p>
<p>But then:</p>
<p>
$$\min_x \mathcal{L}(x,\lambda,\mu) \leq J(x) \ \ \forall x, \lambda \geq 0, \mu$$
</p>
<p>In particular, if $x^*$ is an optimal solution to the original problem, we have:</p>
<p>
$$\min_x \mathcal{L}(x,\lambda,\mu) \leq J(x^*) \ \ \forall \lambda \geq 0, \mu$$
</p>
<p>But $J(x^*) = f_0(x^*) = p^*$, so we have:</p>
<p>
$$\min_x \mathcal{L}(x,\lambda,\mu) \leq p^* \ \ \forall \lambda \geq 0, \mu \tag{2}$$
</p>
<p>Designating the original problem as the <em>primal</em>, we call $g(\lambda, \mu) := \min_x \mathcal{L}(x, \lambda, \mu)$ the <em>dual function</em> since it represents a lower bound on the primal optimal value.</p>
<p>Then inequality $(3)$ becomes our first formulation of Weak Duality.</p>
<p>
$$g(\lambda, \mu) \leq p^* \ \ \forall \lambda \geq 0, \mu \tag{Weak Duality 1}$$
</p>
<p>From here, we move to define the <em>dual problem</em>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Lagrange-Dual-Problem">
<a class="anchor" href="#The-Lagrange-Dual-Problem" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Lagrange Dual Problem<a class="anchor-link" href="#The-Lagrange-Dual-Problem"> </a>
</h2>
<p>It's natural, at this point, to ask what the <em>tightest</em> lower bound $d^*$ on $p^*$ is. That is, what's the largest $d^*$ s.t. $d^* \leq p^*$?</p>
<p>This amounts to finding the values $\lambda^* \geq 0$, and $\mu^*$ for which $g(\lambda^*, \mu^*)$ is maximized. We call this the <em>Lagrange dual problem</em> (or simply the <em>dual problem</em>).</p>
<p>As a general optimization problem, it can be stated as:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$
\begin{cases}
\max_{\lambda, \mu}: g(\lambda, \mu)
\\
s.t.: \lambda \geq  0
\end{cases}
$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Looking at the above, we can see why the Lagrange multipliers are referred to as the <em>dual variables</em> — they simply end up being the variables of the dual problem.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Weak-Duality">
<a class="anchor" href="#Weak-Duality" aria-hidden="true"><span class="octicon octicon-link"></span></a>Weak Duality<a class="anchor-link" href="#Weak-Duality"> </a>
</h1>
<p>We've already stated Weak Duality as $(4)$. In this section, we give a few alternate formulations.</p>
<p>If $\lambda^* \geq 0$, and $\mu^*$ are dual optimal, that is $g(\lambda^*, \mu^*) = d^*$, then we have Weak Duality in terms of the tightest lower bound as:</p>
<p>
$$d^* \leq p^* \tag{Weak Duality 2}$$
</p>
<h2 id="The-Max-Min-Characterization">
<a class="anchor" href="#The-Max-Min-Characterization" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Max-Min Characterization<a class="anchor-link" href="#The-Max-Min-Characterization"> </a>
</h2>
<p>Since $g(\lambda, \mu) := \min_{x} \mathcal{L}(x, \lambda, \mu)$. The dual optimal, as can be seen from the dual problem, is:
$$d^* = \max_{\lambda \geq 0, \mu} \left\{ \min_x \mathcal{L} (x, \lambda, \mu) \right\} \tag{4}$$</p>
<p>We will now see that the primal optimal can be similarly expressed as:</p>
<p>
$$p^* = \min_x \left\{ \max_{\lambda \geq 0, \mu} \mathcal{L} (x, \lambda, \mu) \right\} \tag{4}$$
</p>
<p>To see this note that, for a fixed $x$, maximizing the Lagrangian over $\lambda \geq 0$ and $\mu$ recovers $\mathcal{J}(x)$ — the unconstrained problem with the infinitely-hard penalty. 
That is:</p>
<p>
$$\max_{\lambda \geq 0, \mu} \mathcal{L}(x, \lambda, \mu) = \mathcal{J}(x) \ \ \forall x \tag{5}$$
</p>
<p>To prove this claim, fix $x$ and consider two possibilities. If all inequality constraints are respected, that is $f_i(x) \leq 0$ $\forall i$, then, in order to maximize $\mathcal{L}$, the best we can do is set $\lambda_i = 0$ $\forall i$ which results in the optimal value $f_0(x)$. In case when <em>any</em> inequality constraint is violated, that is $f_i(x) &gt; 0$ for some $i$, the result of maximizing $\mathcal{L}$ is $\infty$ by choosing $\lambda_i \rightarrow \infty$ and $\lambda_j = 0$ $\forall j \ne i$.</p>
<p>Using similar logic, if all equality constraints are respected then $h_i(x) = 0$ $\forall i$. In this case any choice of $\mu$ results in $J(x) = f_0(x)$. If, on the other hand, some equality constraint is violated then $h_i(x) \ne 0$ for some $i$. By choosing $\mu \rightarrow \pm \infty$, where the sign depends on the direction of the violation, the result can be made $\infty$.</p>
<p>Minimizing equation $(5)$ over $x$ yields:</p>
<p>
$$ \min_x \mathcal{J}(x) = \min_x \left\{ \max_{\lambda \geq 0, \mu} \mathcal{L}(x, \lambda, \mu) \right\}$$
</p>
<p>But $\min_x \mathcal{J}(x) = p^*$, concluding the proof of claim $(4)$.</p>
<p>This gives us a way to express Weak Duality in a more symmetric way.</p>
<p>
$$\max_{\lambda \geq 0, \mu} \left\{ \min_x \mathcal{L} (x, \lambda, \mu) \right\} \leq \min_x \left\{ \max_{\lambda \geq 0, \mu} \mathcal{L} (x, \lambda, \mu) \right\} \tag{Weak Duality 3}$$
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Max-Min-Inequality-and-its-Interpretations">
<a class="anchor" href="#Max-Min-Inequality-and-its-Interpretations" aria-hidden="true"><span class="octicon octicon-link"></span></a>Max-Min Inequality and its Interpretations<a class="anchor-link" href="#Max-Min-Inequality-and-its-Interpretations"> </a>
</h2>
<p>Weak Duality can also be derived through a non-optimization lens using the quantities</p>
<p>
$$\max_{\lambda \geq 0, \mu} \left\{ \min_x \mathcal{L} (x, \lambda, \mu) \right\} \ \ \textrm{and} \ \ \min_x \left\{ \max_{\lambda \geq 0, \mu} \mathcal{L} (x, \lambda, \mu) \right\}$$
</p>
<p>by using the <a href="https://en.wikipedia.org/wiki/Max%E2%80%93min_inequality">max-min inequality</a>.</p>
<h3 id="The-Max-Min-Inequality">
<a class="anchor" href="#The-Max-Min-Inequality" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Max-Min Inequality<a class="anchor-link" href="#The-Max-Min-Inequality"> </a>
</h3>
<p>The max-min inequality makes no assumptions about the function. It's simply true for all functions of the form $f: X \times Y \rightarrow \mathbb{R}$, and it states that:
$$
\inf_{y\in Y} \left\{ \sup_{x\in X} f(x,y) \right\} \geq \sup_{x\in X} \left\{ \inf_{y\in Y} f(x,y) \right\}
$$</p>
<p>Since no assumption is made on $f$, the inequality certainly also holds for $\mathcal{L}$. And, since we're in the special case where the optima are assumed to exist, the functions  attain the optima. That is, we can replace $\sup$ and $\inf$ in the inequality with $\max$ and $\min$. This results in the symmetric formulation of Weak Duality as stated above.</p>
<p>All that remains in establishing Weak Duality is to prove the max-min inequality.</p>
<p>For any $f$, and $x \in X$, $y \in Y$ we have:

$$f(x,y) \geq \min_x f(x,y) \ \ \forall y$$

The right hand side is now only a function of $y$, so maximizing both sides w.r.t. $y$ yields: 

$$ \max_y f(x,y) \geq \max_y \left\{ \min_x f(x,y) \right\} \ \ \forall x$$

The right hand side is now a constant, so minimizing both sides w.r.t. $x$ results in the desired conclusion.

$$\min_x \left\{ \max_y f(x,y) \right\} \geq \max_y \left\{ \min_x f(x,y) \right\}$$
</p>
<h3 id="Game-Theoretic-Interpretation">
<a class="anchor" href="#Game-Theoretic-Interpretation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Game-Theoretic Interpretation<a class="anchor-link" href="#Game-Theoretic-Interpretation"> </a>
</h3>
<p>An intuitive way to see the validity of the max-min inequality comes from Game Theory.</p>
<p>Suppose two players $X$, and $Y$, are playing a game in which player $X$'s goal is to minimize the score $f(X,Y)$ whereas player $Y$'s goal is to maximize it. Suppose, per the rules of the game, player $X$ has the first turn. Player $X$ plays $x$ with no knowledge of how player $Y$ will respond. Player $Y$, then, plays $y(x)$ which is a choice informed by that of player $X$. So player $Y$ has a clear tactical advantage in this game.</p>
<p>The quintessential example is the game of <em>Rock, Paper, Scissors</em>. The simultaneous game is fair. However, if one player gets to see the other players' choice first, they will win every time.</p>
<p>Conversely, If a second game is played such that player $Y$ goes first, the advantage lies with player $X$.</p>
<p>Formally, suppose the game is described by $f(x,y)$ where $x$ and $y$ represent the choices available to players $X$ and $Y$ respectively.</p>
<p>The score of the first game will be $\min_x \left\{ \max_y f(x,y) \right\}$.</p>
<p>Similarly, in the second game the score will be $\max_y \left\{ \max_x f(x,y) \right\}$.</p>
<p>Since player $Y$, whose goal is to maximize the score, has an advantage in the first game, we have the max-min inequality</p>
<p>
$$\min_x \left\{ \max_y f(x,y) \right\} \geq \max_y \left\{ \max_x f(x,y) \right\}$$
</p>
<h3 id="Price-or-Tax-Interpretation">
<a class="anchor" href="#Price-or-Tax-Interpretation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Price or Tax Interpretation<a class="anchor-link" href="#Price-or-Tax-Interpretation"> </a>
</h3>
<p>\\  TO BE ADDED ///</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Strong-Duality">
<a class="anchor" href="#Strong-Duality" aria-hidden="true"><span class="octicon octicon-link"></span></a>Strong Duality<a class="anchor-link" href="#Strong-Duality"> </a>
</h1>
<p>Strong Duality is the case in which the primal and the dual optima agree. That is:</p>
<p>
$$p^* = d^* \tag{Strong Duality 1}$$
</p>
<p>Alternatively, in its max-min characterization:</p>
<p>
$$\max_{\lambda \geq 0, \mu} \left\{ \min_x \mathcal{L} (x, \lambda, \mu) \right\} = \min_x \left\{ \max_{\lambda \geq 0, \mu} \mathcal{L} (x, \lambda, \mu) \right\} \tag{Strong Duality 2}$$
</p>
<p>Optimization problems that exhibit this property are called Strongly Dual.</p>
<p>We will see that all linear programs are Strongly Dual. When it comes to non-linear optimization, however, Strong Duality is not guaranteed. Sufficient conditions for Strong Duality exist, however, and we will give them shortly.</p>
<p>As we shall see, Strong Duality unlocks powerful optimality conditions and structural insights about the problem. So, knowing in advance whether or not a problem is Strongly Dual will be beneficial to us.</p>
<h2 id="An-Easier-Dual-Problem">
<a class="anchor" href="#An-Easier-Dual-Problem" aria-hidden="true"><span class="octicon octicon-link"></span></a>An Easier Dual Problem<a class="anchor-link" href="#An-Easier-Dual-Problem"> </a>
</h2>
<p>As mentioned briefly in the introduction, duality gives us the option of solving our original, constrained optimization problem in a different, possibly easier, way. Let's qualify this statement further.</p>
<p>The original, possibly non-convex, problem was that of finding the primal optimal value $p^* = \min_x \left\{ \max_{\lambda \geq 0, \mu} \mathcal{L} (x, \lambda, \mu) \right\}$.</p>
<p>This amounts to fixing a value for $x$ and then maximizing $\mathcal{L}$ over $\lambda \geq 0$, $\mu$. As we've mentioned before this recovers $J(x)$, a non-differentiable function.</p>
<p>Meanwhile, the dual problem is that of finding the dual optimal value $d^* = \max_{\lambda \geq 0, \mu} \left\{ \min_x \mathcal{L} (x, \lambda, \mu) \right\}$.</p>
<p>This amounts to fixing $\lambda \geq 0$, $\mu$ and then minimizing $\mathcal{L}$ over $x$.</p>
<p>Minimizing the Lagrangian over $x$ may still be hard, but at least it lends itself to using the method of unconstrained optimization. Furthermore, the resulting dual function $g(\lambda, \mu) = \min_x \mathcal{L}(x, \lambda, \mu)$ is <em>always</em> easy to maximize over $\lambda \geq 0$ and $\mu$ since it's concave with a linear constraint $\lambda \geq 0$. The reason it's concave, of course, is that it's the pointwise minimum of linear functions in $\lambda$, and $\mu$.</p>
<p>If Strong Duality holds, and hence solving the dual is the same as solving the primal, we have found an easier approach to the original problem. However, if Strong Duality fails to hold not all is lost. We can still obtain a useful lower bound for the primal optimal value through Weak Duality.</p>
<h2 id="Slater's-Condition---Sufficient-Condition-for-Strong-Duality">
<a class="anchor" href="#Slater's-Condition---Sufficient-Condition-for-Strong-Duality" aria-hidden="true"><span class="octicon octicon-link"></span></a>Slater's Condition - Sufficient Condition for Strong Duality<a class="anchor-link" href="#Slater's-Condition---Sufficient-Condition-for-Strong-Duality"> </a>
</h2>
<p>Even though not all Strongly Dual problems are convex and not all convex programs are Strongly Dual, convexity together with <em>Slater's Condition</em> is sufficient for Strong Duality.</p>
<blockquote>
<p><strong>Slater's Condition:</strong>   $\exists \ \hat x$ s.t. $f_i(\hat x) &lt; 0$, and $h_i(\hat x) = 0$ $\forall i$.<br></p>
</blockquote>
<p><br>
</p>
<div class="flash">
    <svg class="octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>The equality constraints $h_i(\hat x) = 0$ are often stated as linear equality constraints $A \hat x = b$ in certain sources. This is simply due to the observation that equality constraints are convex constraints if and only if all of the $h_i$’s are linear.
</div>
<br>
<p>Informally, Slater's Condition says that the existence of a feasible point which has margin w.r.t. all the inequality constraints is needed in addition to convexity. In even simpler terms, the feasible region must have an interior point.</p>
<p>The sufficient condition for Strong Duality is then</p>
<blockquote>
<p><strong>Sufficient Condition for Strong Duality:</strong>   Any convex optimization problem satisfying Slater's Condition has Strong Duality.<br></p>
</blockquote>
<p>The proof of this is beyond what we're trying to achieve in this post. However we motivate it geometrically in the following paragraph.</p>
<h3 id="Geometric-Intuition-Behind-Slater's-Condition">
<a class="anchor" href="#Geometric-Intuition-Behind-Slater's-Condition" aria-hidden="true"><span class="octicon octicon-link"></span></a>Geometric Intuition Behind Slater's Condition<a class="anchor-link" href="#Geometric-Intuition-Behind-Slater's-Condition"> </a>
</h3>
<p>\\  TO BE ADDED ///</p>
<h2 id="Complementary-Slackness---A-Consequence-of-Strong-Duality">
<a class="anchor" href="#Complementary-Slackness---A-Consequence-of-Strong-Duality" aria-hidden="true"><span class="octicon octicon-link"></span></a>Complementary Slackness - A Consequence of Strong Duality<a class="anchor-link" href="#Complementary-Slackness---A-Consequence-of-Strong-Duality"> </a>
</h2>
<p>Suppose $x^*$ is a primal optimal solution and $(\lambda^*, \mu^*)$ is a dual optimal solution. An immediate consequence of Strong Duality is the fact that $\lambda^*_i f_i(x^*) = 0 \ \ \forall i$: a fact often called <em>Complementary Slackness</em>.</p>
<p>Informally, if a primal constraint at a primal optimal solution $x^*$ is <em>loose</em>, that is $f_i(x^*) \ne 0$, then its corresponding dual variable $\lambda^*_i$ in the optimal dual solution $\lambda^*$ must be zero. On the other hand, if a primal constraint is <em>tight</em> at $x^*$, nothing can be said about its corresponding dual variable.</p>
<h3 id="Proof-of-Complementary-Slackness">
<a class="anchor" href="#Proof-of-Complementary-Slackness" aria-hidden="true"><span class="octicon octicon-link"></span></a>Proof of Complementary Slackness<a class="anchor-link" href="#Proof-of-Complementary-Slackness"> </a>
</h3>
<p>In general, for any $x$, and $(\lambda, \mu)$ we have</p>
<p>
$$g(\lambda, \mu) = \min_x \mathcal{L}(x, \lambda, \mu) \leq \mathcal{L}(x, \lambda, \mu) \leq \max_{\lambda \geq 0, \mu} \mathcal{L}(x, \lambda, \mu) = J(x)$$
</p>
<p>Suppose $x^*$ and $(\lambda^*, \mu^*)$ are primal-dual optimal.</p>
<p>Since $J$ is, by construction, equivalent to the original problem, $J(x^*) = f_0(x^*)$.</p>
<p>Furthermore, by Strong Duality, we have $$d^* = g(\lambda^*, \mu^*) = f_0(x^*) = p^*$$</p>
<p>Which forces the following result in the first inequality</p>
<p>
$$g(\lambda^*, \mu^*) = \mathcal{L}(x^*, \lambda^*, \mu^*) = f_0(x^*)$$
</p>
<p>Then
$$\begin{aligned} 
f_0(x^*) &amp;= \mathcal{L}(x^*, \lambda^* \mu^*)  \\ 
&amp;= f_0(x^*) + \sum_{i=1}^m \lambda^*_i f_i(x^*) + \sum_{i=1}^p \mu^*_i h_i(x^*) \\
&amp;\leq f_0(x^*)
\end{aligned}
$$</p>
<p>To see why the last inequality holds, note that $\sum_{i=1}^p \mu_i^* h_i(x^*) = 0$ since $h_i(x^*) = 0 \ \ \forall i$ by feasibility of $x^*$. Then again, by feasibility of $x^*$, $\forall i$ $f_i(x^*) \leq 0$. And since, by construction of $\mathcal{L}$, $\lambda \geq 0$ we have $\sum_{i=1}^m \lambda^*_i f_i(x^*) \leq 0$.</p>
<p>But taken altogether this says $f_0(x^*) \leq f_0(x^*)$ which can <em>only</em> be true through strict equality. Then it must be the case that $\sum_{i=1}^m \lambda^*_i f_i(x^*) = 0$.</p>
<p>Being a sum of non-positive terms, this can <em>only</em> happen if $\lambda^*_i f_i(x^*) = 0 \ \ \forall i$ which is what we wanted to show.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Optimality-Conditions">
<a class="anchor" href="#Optimality-Conditions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Optimality Conditions<a class="anchor-link" href="#Optimality-Conditions"> </a>
</h2>
<p>Strong Duality obtains powerful necessary and sufficient conditions for optimality known as <em>Karush–Kuhn–Tucker (KKT) Conditions</em>. We will see that in the absence of Strong Duality, the KKT Conditions are necessary, but insufficient, for optimality. In the presence of Strong Duality KKT Conditions become a <em>certificate of optimality</em>.</p>
<p>We will also see that the KKT Conditions are a generalization of unconstrained optimization for the constrained case.</p>
<h3 id="Karush-Kuhn-Tucker-(KKT)-Conditions">
<a class="anchor" href="#Karush-Kuhn-Tucker-(KKT)-Conditions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Karush-Kuhn-Tucker (KKT) Conditions<a class="anchor-link" href="#Karush-Kuhn-Tucker-(KKT)-Conditions"> </a>
</h3>
<p>At first, we list the KKT conditions.</p>
<blockquote>
<p><strong>KKT Conditions:</strong>   $x^*, (\lambda^*, \mu^*)$ satisfy the KKT conditions if the following hold: </p>
<ol>
<li>$\nabla_x f_0(x^*) + \sum_{i \in I} \lambda^*_i\nabla_xf_i(x^*) + \sum_{i=1}^p \mu^*_i\nabla_xh_i(x^*) = 0$ where $I$ is the set of indices of the active inequality constraints.</li>
<li>$\lambda^*_if_i(x^*) = 0 \ \ \forall i$</li>
<li>$g_i(x^*) \leq 0 \ \ \forall i$ </li>
<li>$h_i(x^*) = 0 \ \ \forall i$ </li>
<li>$\lambda^* \geq 0$
<br>
</li>
</ol>
</blockquote>
<p>Clearly these conditions apply only to problems with differentiable objective and constraints. If one (or more) of the objective or constraints is not differentiable there is a subdifferential version of the KKT Conditions. However, this is beyond the scope of this post.</p>
<p>Now, as promised, we give the necessary and sufficient optimality condition.</p>
<blockquote>
<p><strong>Certificate of Optimality</strong>   If Strong Duality holds, then $x^*, (\lambda^*, \mu^*)$ are primal-dual optimal if and only if they satisfy the KKT conditions. 
<br></p>
</blockquote>
<h3 id="Motivating-the-KKT-Conditions">
<a class="anchor" href="#Motivating-the-KKT-Conditions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Motivating the KKT Conditions<a class="anchor-link" href="#Motivating-the-KKT-Conditions"> </a>
</h3>
<p>As we saw in the section on Complementary Slackness</p>
<p>
$$g(\lambda^*, \mu^*) = \min_x \mathcal{L} (x, \lambda^*, \mu^*) = \mathcal{L}(x^*, \lambda^*, \mu^*)$$
</p>
<p>That is $x^*$, which is the minimizer of the original problem $J(x)$, also minimizes $\mathcal{L}(x, \lambda^*, \mu^*)$.</p>
<p>This is the result we need in order to finally apply the first-order necessary condition of unconstrained optimization. Doing so yields the first KKT condition called the <em>Stationarity Condition</em>.</p>
<p>$\nabla_x \mathcal{L}(x^*, \lambda, \mu) = \nabla f_0(x^*) + \sum_{i=1}^m \lambda^*_i \nabla f_i(x^*) + \sum_{i=1}^p \mu^*_i \nabla h_i(x^*) = 0 \tag{1}$</p>
<p>The second KKT Condition comes from Complementary Slackness which is an immediate consequence of Strong Duality.</p>
<p>
$$\lambda^*_i f_i(x^*) = 0 \ \ \forall i \tag{2}$$
</p>
<p>In words, Complementary Slackness says that if a constraint $f_i$ is loose at the primal optimal $x^*$, then its corresponding dual optimal variable $\lambda^*_i = 0$. So, the second KKT condition can be seen to modify the first. We can interpret $\lambda^*_i = 0$ as meaning that we can disregard the inactive constraint $f_i$ in the first KKT Condition altogether.</p>
<p>Finally, KKT Conditions 3-4, called <em>Feasibility Conditions</em>, simply follow from the assumption that $x^*$, and $(\lambda^*, \mu^*)$ are primal-dual optimal, and hence primal-dual feasible.</p>
<p>This concludes the proof that if $x^*$, $(\lambda^*, \mu^*)$ is primal-dual optimal with zero duality gap then $x^*$, $(\lambda^*, \mu^*)$ is a KKT pair. The converse is also true, but harder to prove in the non-linear case. We offer its proof for linear programs only later on in this post.</p>
<h3 id="KKT-as-a-Generalization-of-Unconstrained-Optimization">
<a class="anchor" href="#KKT-as-a-Generalization-of-Unconstrained-Optimization" aria-hidden="true"><span class="octicon octicon-link"></span></a>KKT as a Generalization of Unconstrained Optimization<a class="anchor-link" href="#KKT-as-a-Generalization-of-Unconstrained-Optimization"> </a>
</h3>
<p>SAME AS GRAD F = 0 BUT RESTRICTS DIRECTIONS TO FEASIBLE ONES</p>
<p>ALSO REDUCES TO FIRST ORDER CONDITIONS FOR ALREADY UNCONSTRAINED PROBLEM.</p>
<h3 id="Stationarity-Condition---Geometric-Perspective">
<a class="anchor" href="#Stationarity-Condition---Geometric-Perspective" aria-hidden="true"><span class="octicon octicon-link"></span></a>Stationarity Condition - Geometric Perspective<a class="anchor-link" href="#Stationarity-Condition---Geometric-Perspective"> </a>
</h3>
<p>The Stationarity Condition has a strong geometric flavor in the case where the level sets of</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Saddle-Point-Interpretation">
<a class="anchor" href="#Saddle-Point-Interpretation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Saddle Point Interpretation<a class="anchor-link" href="#Saddle-Point-Interpretation"> </a>
</h2>
<p>In this section, we will give the saddle point interpretation of Strong Duality through the <em>Saddle Point Theorem</em> which states the following.</p>
<blockquote>
<p><strong>Saddle Point Theorem:</strong>   If $x^*$ and $(\lambda^*, \mu^*)$ are primal and dual optimal solutions for a convex problem which satisfies Slater's Condition, they form a saddle point of the associated Lagrangian. Conversely, if $(x^*,\lambda^*, \mu^*)$ is a saddle point of a Lagrangian, then $x^*$ is a primal optimal, and $(\lambda^*, \mu^*)$ a is dual optimal of the associated Strongly Dual problem.<br></p>
</blockquote>
<p><br>
</p>
<div class="flash">
    <svg class="octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>This isn’t a necessary condition of Strong Duality since not all Strongly Dual problems satisfy the Sufficient Condition for Strong Duality. That is, it would be incorrect to replace "a convex problem which satisfies Slater’s Condition" in the above theorem with "a Strongly Dual problem." In fact, not all Strongly Dual problems are convex to begin with, in which case the Lagrangian has no saddle points to speak of. 
</div>
<br>
<p>First, let's show that the max-min inequality holds with strict equality at saddle points. This will yield one direction of the Saddle Point Theorem proof.</p>
<h3 id="Max-Min-Equality-at-Saddle-Points">
<a class="anchor" href="#Max-Min-Equality-at-Saddle-Points" aria-hidden="true"><span class="octicon octicon-link"></span></a>Max-Min Equality at Saddle Points<a class="anchor-link" href="#Max-Min-Equality-at-Saddle-Points"> </a>
</h3>
<p>For certain types of functions, informally speaking those that are saddle-shaped, the max-min inequality holds with strict equality.</p>
<p>The proof is as follows.</p>
<p>Let $f: X \times Y \rightarrow \mathbb{R}$ be saddle-shaped.</p>
<p>We call a point $(\hat x, \hat y) \in X \times Y$ a <em>saddle-point</em> of $f(x,y)$ if $f(\hat x, y) \leq f(\hat x, \hat y) \leq f(x, \hat y)$ for all $x \in X$ and $y \in Y$.</p>
<p>In other words, $\hat x$ minimizes $f(x, \hat y)$ over $X$, and $\hat y$ maximizes $f(\hat x,y)$ over $Y$. That is</p>
<p>
$$f(\hat x, \hat y) = \inf_{x \in X} f(x, \hat y) \ \ \textrm{and} \ \ f(\hat x, \hat y) = \sup_{y \in Y} f(\hat x, y)$$
</p>
<p>But then</p>
<p>
$$\sup_{y \in Y} \left\{ \inf_{x \in X} f(x,y) \right\} = \inf_{x \in X} f(x, \hat y) = f(\hat x, \hat y) \ \ \textrm{and} \ \ \inf_{x \in X} \left\{ \sup_{y \in Y} f(x,y) \right\} = \sup_{y \in Y} f(\hat x, y) = f(\hat x, \hat y)$$
</p>
<p>So the order of optimization over $X$ and $Y$ does not matter. That is, we're in the strict case of the max-min inequality.</p>
<p>
$$\sup_{y \in Y} \left\{ \inf_{x \in X} f(x,y) \right\} = \inf_{x \in X} \left\{ \sup_{y \in Y} f(x,y) \right\}$$
</p>
<h3 id="Proof-of-Saddle-Point-Theorem">
<a class="anchor" href="#Proof-of-Saddle-Point-Theorem" aria-hidden="true"><span class="octicon octicon-link"></span></a>Proof of Saddle Point Theorem<a class="anchor-link" href="#Proof-of-Saddle-Point-Theorem"> </a>
</h3>
<p><strong>$\implies$:</strong></p>
<p>Suppose $x^*$ and $(\lambda^*, \mu^*)$ are primal and dual optimal solutions for a convex problem which satisfies Slater's Condition. Then the problem is Strongly Convex by the Sufficient Condition for Strong Duality.</p>
<p>\\  NEED KKT CONDITIONS  ///</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="LINEAR-PROGRAMS">
<a class="anchor" href="#LINEAR-PROGRAMS" aria-hidden="true"><span class="octicon octicon-link"></span></a>LINEAR PROGRAMS<a class="anchor-link" href="#LINEAR-PROGRAMS"> </a>
</h1>
<p>BEST WAY TO UNDERSTAND INTUITIVELY COMPLEMENTARY SLACKNESS AND OTHER PROPERTIES OF STRING DUALITY IN KKT CONDITIONS</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Weak-Duality-in-Linear-Programs">
<a class="anchor" href="#Weak-Duality-in-Linear-Programs" aria-hidden="true"><span class="octicon octicon-link"></span></a>Weak Duality in Linear Programs<a class="anchor-link" href="#Weak-Duality-in-Linear-Programs"> </a>
</h1>
<p>Let's now focus on linear programs.</p>
<p>Suppose the primal is an LP of the form</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$
\begin{cases}
\min_x: c^Tx
\\
s.t.: \begin{aligned} &amp;Ax \geq b
\\ 
&amp;x \geq 0
\end{aligned}
\end{cases}
$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>By constructing the Lagrangian and going through the steps above we can show its dual is for the form</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$
\begin{cases}
\max_p: b^Tp
\\
s.t.: \begin{aligned} &amp;A^Tp \leq c
\\ 
&amp;p \geq 0
\end{aligned}
\end{cases}
$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Weak Duality states</p>
<blockquote>
<p><strong>Weak Duality:</strong>   For any primal feasible $x$ and for all dual feasible $p$, $c^Tx \geq b^Tp$.<br></p>
</blockquote>
<p>That is, any dual feasible solution $b^Tp$ is a <em>lower bound</em> for all primal feasible solutions $c^Tx$. Conversely, any primal feasible solution $c^Tx$ is an <em>upper bound</em> for all dual feasible solutions $b^Tp$.</p>
<h2 id="Proof-of-Weak-Duality">
<a class="anchor" href="#Proof-of-Weak-Duality" aria-hidden="true"><span class="octicon octicon-link"></span></a>Proof of Weak Duality<a class="anchor-link" href="#Proof-of-Weak-Duality"> </a>
</h2>
<p>Let $(p, x)$ be respectively dual-primal feasible. Then $c^Tx = x^Tc \geq x^TA^Tp \geq b^Tp$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Strong-Duality">
<a class="anchor" href="#Strong-Duality" aria-hidden="true"><span class="octicon octicon-link"></span></a>Strong Duality<a class="anchor-link" href="#Strong-Duality"> </a>
</h1>
<p>While Weak Duality is a useful result, the real strength of duality theory lies in <em>Strong Duality</em>. Strong duality is a re-statement of Von Neumann's <a href="https://en.wikipedia.org/wiki/Minimax_theorem">Minimax Theorem</a> which lays out the conditions for which the max-min inequality holds with strict equality. Roughly speaking, it holds for functions that are saddle-shaped — convex in one variable and concave in the another.</p>
<p>Instead of proving the Minimax Theorem in the general case, we will stay topical and prove Strong Duality for LP's. That is, the Minimax Theorem as it pertains to the special case of linear programs...</p>
<blockquote>
<p><strong>Strong Duality:</strong>   If the primal is feasible and bounded with optimal $x^*$ then the dual is also feasible and bounded. Furthermore, if the dual has optimum $p^*$ then $c^Tx^* = b^Tp^*$.<br></p>
</blockquote>
<p>To prove Strong Duality, we require <em>Farkas' Lemma</em>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Farkas'-Lemma">
<a class="anchor" href="#Farkas'-Lemma" aria-hidden="true"><span class="octicon octicon-link"></span></a>Farkas' Lemma<a class="anchor-link" href="#Farkas'-Lemma"> </a>
</h2>
<p><em>Farkas' Lemma</em> belongs to the class of theorems called <em>Theorems of the Alternative</em> — these are a theorems stating that exactly one of two statements holds true.</p>
<p>The lemma simply states that a given vector $c$ is either a <a href="https://v-poghosyan.github.io/blog/optimization/applied%20mathematics/proofs/2022/01/23/Optimization-Review-of-Linear-Algebra-and-Geometry.html#Conic-Combinations-of-%24n%24-Points">conic combination</a> of $a_i$'s for some $i \in I$, or it's separated from their cone by some hyperplane.</p>
<p>We state Farkas' Lemma without offering proof since it has such an obvious geometric interpretation.</p>
<blockquote>
<p><strong>Farkas' Lemma:</strong>   For any vector $c$ and $a_i \ \ (i \in I)$ either the first or the second statement holds:   </p>
<ul>
<li>$\exists p \geq 0$ s.t. $c = \sum_{i \in I} a_ip_i$</li>
<li>$\exists$ vector $d$ s.t. $d^Ta_i \geq 0 \ \ \forall i \in I$ but $d^Tc &lt; 0$</li>
</ul>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Proof-of-Strong-Duality-in-LP's">
<a class="anchor" href="#Proof-of-Strong-Duality-in-LP's" aria-hidden="true"><span class="octicon octicon-link"></span></a>Proof of Strong Duality in LP's<a class="anchor-link" href="#Proof-of-Strong-Duality-in-LP's"> </a>
</h2>
<p>\\ ANOTHER SUFFICIENT CONDITION FOR STRONG DUALITY IS BEING A LINEAR PROGRAM. THE PROOF BELOW IS INDEPENDENT OF PAST SUFFICIENT CONDITIONS. ///</p>
<p>The proof is by construction.</p>
<p>Suppose $x^*$ is a primal optimal solution. Let the set $I_{x^*} = \{ i : a_i^Tx^* = b_i\}$ be the set of the indices of the active constraints at $x^*$. Our goal is to construct a dual optimal solution $p^*$ s.t. $c^Tx^* = b^Tp^*$.</p>
<p>Let $d$ be any vector that satisfies $d^Ta_i \geq 0 \ \ \forall i \in I_{x^*}$. That is, $d$ is a feasible direction w.r.t. to all the active constraints.</p>
<p>A small, positive $\epsilon$-step in the direction of $d$ results in point $x^* + \epsilon d$ that's still feasible. The fact that the step is small is what guarantees no inactive constraints are violated.</p>
<p>Let's compare the value of the objective at $x^* + \epsilon d$ to the value of the objective at $x^*$.</p>
<p>By the assumption that $x^*$ is optimal, we have $c^Tx^* \leq c^T(x^* + \epsilon d) = c^Tx^* + \epsilon c^Td$. Thus, $c^Td = d^Tc \geq 0$
</p>
<div class="flash">
    <svg class="octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>$d^Tc$ is nothing but the <em>directional derivative</em> at the minimizer $x^*$. It is a <em>first-order necessary-condition</em> that the <em>directional derivative</em> in any feasible direction $d$ be non-negative at any minimizer $x^*$. This is analogous to the first-derivative test for scalar-valued functions. So, this result should have been expected...
</div>
<br>
<p>But since $d$ is a vector s.t. $d^Ta_i \geq 0 \ \ \forall i \in I_{x^*}$ and $d^Tc \geq 0$, then $d$ does <em>not</em> separate $c$ from the cone of the $a_i$'s. And since $d$ was arbitrary, this puts us in the setting of Farkas' Lemma. Namely, there exist <em>no</em> vectors $d$ that separate $c$ from the cone. This means the second statement in Farkas' Lemma is violated and the first must be true — $c$ must a conic combination of the $a_i$'s that are active at the minimizer. In other words, $\exists p \geq 0$ s.t. $c = \sum_{i \in I_{x^*}} p_ia_i$. 
</p>
<div class="flash">
    <svg class="octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>$c = \sum_{i \in I_{x^*}} p_ia_i$ should remind us of the Lagrange optimality condition in the general case of convex optimization. Recall that the Lagrange condition states that a point $x^*$ is optimal for a convex problem with objective $f(x)$ and constraints $g_i(x)=0$ if and only if $\exists  \lambda_i$ for each active constraint s.t. $\nabla f(x^*) = \sum_i \lambda_i \nabla g_i(x^*)$. In fact, Farka’s lemma is what underpins the Lagrange condition through the assumption that the non-linear objective $f$ and non-linear constraints $g_i$ behave linearly in a small neighborhood of $x^*$. 
</div>
<br>
<p>But $p$ has dimension equal to only the number of active constraints at $x^*$. To be a dual variable at all, it must have dimension equal to the number of all primal constraints. We extend $p$ to $p^*$ by setting all the entries that do not correspond to the active constraints at $x^*$ to be zero.</p>
<p>That is $p^*_i = \begin{cases} p_i \ \ \textrm{if} \ \  i \in I_{x^*} \\ 0   \ \ \textrm{if} \ \  i \notin I_{x^*} \end{cases}$.</p>
<p>Now $A^Tp^*  = \sum_{i} p^*_ia_i = c$, so any feasibility condition in the dual, whether it be $A^Tp \leq c$, $A^Tp \geq c$, or $A^Tp = c$, is satisfied by $p^*$.</p>
<p>Furthermore, the dual objective at $p^*$ agrees with the primal objective at $x^*$.</p>
<p>
$$b^Tp^* = \sum_{i} b_ip_i^* = \sum_{i \in I_{x^*}} b_ip_i^* + \sum_{i \notin I_{x^*}} b_ip_i^* = \sum_{i \in I_{x^*}} a_i^Tx^*p_i^* = (\sum_{i \in I_{x^*}} p_ia_i^T)x^* = c^Tx^* $$
</p>
<p>However, it still remains to be shown that $p^*$ is dual optimal.</p>
<p>Whenever the primal objective and the dual objective agree on a value, the respective solutions must be primal-dual optimal. This is simply true by Weak Duality, which states that $b^Tp \leq c^Tx^*$ $\forall p$. So, $c^Tx^*$ is an upper bound for any dual feasible solution. But the dual is a maximization problem, so the dual optimal must be $p^*$ s.t. $b^Tp^* = c^Tx^*$.</p>
<p>NOTE THAT WE HAVE CONSTRUCTED THE DUAL OPTIMAL BY EXPLICITY SATISFYING THE KKT CONDITIONS IN THE LINEAR CASE. SO THIS IS THE PROOF THAT KKT PAIR =&gt; PRIMAL/DUAL OPTIMAL.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Theorems-of-the-Alternative">
<a class="anchor" href="#Theorems-of-the-Alternative" aria-hidden="true"><span class="octicon octicon-link"></span></a>Theorems of the Alternative<a class="anchor-link" href="#Theorems-of-the-Alternative"> </a>
</h1>
<p>As mentioned earlier, these are theorems that describe exclusively disjoint scenarios that together comprise the entire outcome space. Formally, these are theorems of the form $A \implies \neg B \land \neg A \implies  B$  where $A$, and $B$ are logical statements.</p>
<p>Note that theorems of equivalence (i.e. theorems of the form <em>'the following are equivalent - TFAE'</em>) can also be formulated as theorems of the alternative. To say that $A$ and $B$ are equivalent means $ A \iff B$. But this breaks down as $A \implies B \land B \implies A$. Letting $\hat B = \neg B$ we can rewrite the above as $A \implies \neg \hat B \land B \implies A$. But, by taking the contrapositive, $B \implies A$ becomes $\neg A \implies \neg B$, which is to say $\neg A \implies \hat B$. In summary, we have shown that $A \iff B$ is equivalent to $A \implies \neg \hat B \land \neg A \implies \hat B$.</p>
<p>So, the class of theorems of the alternative is much broader than it appears and includes theorems of equivalence.</p>
<h2 id="Example-of-a-Theorem-of-the-Alternative">
<a class="anchor" href="#Example-of-a-Theorem-of-the-Alternative" aria-hidden="true"><span class="octicon octicon-link"></span></a>Example of a Theorem of the Alternative<a class="anchor-link" href="#Example-of-a-Theorem-of-the-Alternative"> </a>
</h2>
<p>To see how we can prove a theorem of the alternative, it helps to state one.</p>
<blockquote>
<p><strong>Theorem:</strong>   Exactly one of the following two statements most hold for a given matrix A. </p>
<ol>
<li>$\exists x \ne 0$ s.t. $Ax = 0$ and $x \geq 0$</li>
<li>$\exists p$ s.t. $p^TA &gt; 0$
<br>
</li>
</ol>
</blockquote>
<h3 id="Using-a-Separation-Argument">
<a class="anchor" href="#Using-a-Separation-Argument" aria-hidden="true"><span class="octicon octicon-link"></span></a>Using a Separation Argument<a class="anchor-link" href="#Using-a-Separation-Argument"> </a>
</h3>
<p>At the heart of separation arguments lies this simple fact.</p>
<blockquote>
<p><strong>Separating Hyperplane Theorem:</strong> For any convex set $C$, if a point $\omega \notin C$ then there exists a hyperplane separating $\omega$ and $C$.<br></p>
</blockquote>
<p>Farkas' Lemma, for instance, is proved by a separation argument that uses, as its convex set, the conic combination of the $a_i$'s. The conclusion is immediate since in Farkas' Lemma the first statement plainly says that a vector belongs to the convex set, and the second statement plainly says there exists a separating hyperplane between the two.</p>
<p>This is the pattern all separation arguments must follow. However, in general, it may take a bit of work to define the problem-specific convex set and also to show that the two statements are <em>really</em> talking about belonging to this set, and separation from it. However, once these three things are accomplished the proof is complete.</p>
<p>Using this idea, let's give a proof of the above theorem of the alternative using a separation argument.</p>
<h4 id="Proof">
<a class="anchor" href="#Proof" aria-hidden="true"><span class="octicon octicon-link"></span></a>Proof<a class="anchor-link" href="#Proof"> </a>
</h4>
<p>First order of business is to come up with a convex set.</p>
<p>Let's take $C = \{ z : z = Ay, \sum_i y_i = 1, y \geq 0 \}$ to be the convex hull of the columns of $A$.</p>
<p>The first statement in the theorem was that $\exists x \ne 0$ s.t. $Ax = 0$ and $x \geq 0$.</p>
<p>Since $x \ne 0$ and $x \geq 0$ we can scale as $x$ as $y = \alpha x$ until $\sum_i y_i = 1$.</p>
<p>So, the first statement is equivalent to saying the origin belongs to the convex hull $C$ (i.e. $0 \in C$)</p>
<p>The second statement was that $\exists p$ s.t. $p^TA &gt; 0$. This is equivalent to saying that all the columns of $A$ lie to one side of the separating hyperplane introduced by $p$.</p>
<p>But all $z \in C$ are convex combinations of $A$'s columns. In particular since they're a convex combination they're also a conic combination, so all $z \in C$ also lie on the same side of the hyperplane. That is $p^Tz &gt; 0 \ \ \forall z \in C$.</p>
<p>But, of course, $p^T0 = 0$ (not $&gt; 0$). So, according to the second statement, the origin is separated from $C$.</p>
<p>This concludes the proof since the two statements must be mutually exclusive.</p>
<h3 id="Using-Strong-Duality">
<a class="anchor" href="#Using-Strong-Duality" aria-hidden="true"><span class="octicon octicon-link"></span></a>Using Strong Duality<a class="anchor-link" href="#Using-Strong-Duality"> </a>
</h3>
<p>Strong duality isn't just a tool for applied science, it has important theoretical uses. For instance, now that we've proven it we can use Strong Duality, instead of a separation argument, to prove theorems of the alternative.</p>
<p>Since it gives us feasibility of two different constraint sets, it makes sense to use duality to prove theorems of existence.</p>
<p>Let's take the aforementioned theorem of the alternative for example...</p>
<h4 id="Proof">
<a class="anchor" href="#Proof" aria-hidden="true"><span class="octicon octicon-link"></span></a>Proof<a class="anchor-link" href="#Proof"> </a>
</h4>
<p>To prove the theorem we need to show two things. First, we need to show $1 \implies \neg 2$, then we need to show $\neg 1 \implies 2$.</p>
<p>The $1 \implies \neg 2$ direction is simple.</p>
<p>Suppose $\exists x \ne 0$ s.t. $Ax = 0$ and $x \geq 0$.</p>
<p>Then $\forall p \ \ (p^TA)x = p^T(Ax) = p^T0 = 0$ (not $&gt; 0$).</p>
<p>We tackle the $\neg 1 \implies 2$ direction using duality.</p>
<p>The strategy is to construct a linear program based on $\neg 1$ such that the feasibility of its dual implies $2$.</p>
<p>We can express $\neg 1$ as '$\forall x \ne 0$, either $Ax \ne 0$ or $x &lt; 0$.' Equivalently, '$x \ne 0 \implies Ax \ne 0$ or $x &lt; 0$.' Taking the contrapositive, statement $1$ becomes '$Ax = 0$ and  $x \geq 0 \implies x = 0$.'</p>
<p>So, let's form the LP</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$
\begin{cases}
\max_x: \textbf{1}^Tx
\\
s.t.: \begin{aligned} &amp;Ax = 0
\\ 
&amp;x \geq 0
\end{aligned}
\end{cases}
$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note that $x = 0$ is a feasible solution to the LP. Furthermore, assuming statement $1$ guarantees that $x = 0$ is the only feasible solution. Thus, the LP is feasible and bounded.</p>
<p>By Strong Duality, its dual must also be feasible and bounded.</p>
<p>The dual is...</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$
\begin{cases}
\min_p: \textbf{0}^Tp
\\
s.t.: p^TA \geq \textbf{1}
\end{cases}
$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>... and since it's feasible, $\exists p$ s.t. $p^TA \geq 1 &gt; 0$ which demonstrates the truth of statement $2$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Complementary-Slackness">
<a class="anchor" href="#Complementary-Slackness" aria-hidden="true"><span class="octicon octicon-link"></span></a>Complementary Slackness<a class="anchor-link" href="#Complementary-Slackness"> </a>
</h1>
<p><em>Complementary Slackness</em> is a fundamental property that exists between any primal optimal solution and any dual optimal solution.</p>
<p>In the preceding section on Strong Duality we constructed a dual optimal by setting those of its variables that corresponded to the inactive constraints of the primal optimal to be zero.</p>
<p>This is true in general, for all primal-dual optimal pairs.</p>
<p>If a primal's constraint is loose at a some primal optimal, then the corresponding variable in the dual optimal is zero, and vice versa.</p>
<p>Formally, this can be stated as</p>
<blockquote>
<p><strong>Complementary Slackness:</strong> if $x$ is primal feasible and $p$ is dual feasible, then $x$ and $p$ are respectively optimal iff: </p>
<ol>
<li>$(b_i - \sum_{j} a_{ij}x_j)p_i = 0 \ \ \forall i$</li>
<li>$(\sum_{i} a_{ij}p_i - c_j)x_j = 0  \ \ \forall j$
<br>
</li>
</ol>
</blockquote>
<p>If we recall, in the proof of Strong Duality we constructed a dual optimal by setting those of its variables that corresponded to the primal's slack constraints to be zero. In other words, we constructed a dual optimal in such a way as to satisfy the Complementary Slackness theorem. So, the fact that this generalizes to all primal-dual optima shouldn't surprise us.</p>
<p>However, the above does not constitute a proof of Complementary Slackness, so let's offer one.</p>
<p>Take as a starting point the primal-dual pair</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$
\textrm{P} \ \ 
\begin{cases}
\min_x: c^Tx
\\
s.t.: \begin{aligned} &amp;Ax \geq b
\\ 
&amp;x \geq 0
\end{aligned}
\end{cases}
$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$
\textrm{D} \ \ 
\begin{cases}
\max_p: b^Tp
\\
s.t.: \begin{aligned} &amp;A^Tp \leq c
\\ 
&amp;p \geq 0
\end{aligned}
\end{cases}
$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Proof-of-Complementary-Slackness">
<a class="anchor" href="#Proof-of-Complementary-Slackness" aria-hidden="true"><span class="octicon octicon-link"></span></a>Proof of Complementary Slackness<a class="anchor-link" href="#Proof-of-Complementary-Slackness"> </a>
</h2>
<p><strong>Sufficiency $\impliedby$:</strong></p>
<p>Suppose both equalities hold.</p>
<p>Summing each over all $i$'s and $j$'s respectively and adding the results we get</p>
<p>
$$\sum_i \left(b_i - \sum_j a_{ij}x_j \right)p_i + \sum_j \left( \sum_i a_{ij}p_i - c_j \right)x_j = 0$$
</p>
<p>Which simplifies to</p>
<p>
$$\sum_i b_ip_i - \sum_i \sum_j a_{ij}x_jy_i + \sum_j \sum_i a_{i,j}y_ix_j - \sum_j c_jx_j = 0$$
</p>
<p>Or, in matrix-vector form</p>
<p>
$$b^Tp - p^TAx + p^TAx - c^Tx = 0$$
</p>
<p>The middle two terms cancel, and we get $b^Tp = c^Tp$.</p>
<p>By Weak Duality, $x$ and $p$ are primal-dual optimal.</p>
<p><strong>Necessity $\implies$:</strong></p>
<p>Suppose $x$ and $p$ are primal-dual optimal.</p>
<p>By Strong Duality $b^Tp = c^Tx$.</p>
<p>In other words, $b^Tp - c^Tx = 0$. Adding and subtracting the terms canceled in the first part, we can bring the sum to the form</p>
<p>
$$b^Tp - p^TAx + p^TAx - c^Tx = 0$$
</p>
<p>Which is, once again, the same as</p>
<p>
$$\sum_i \left(b_i - \sum_j a_{ij}x_j \right)p_i + \sum_j \left( \sum_i a_{ij}p_i - c_j \right)x_j = 0$$
</p>
<p>But $p$ is dual feasible, so $p_i \geq 0 \ \ \forall i$. And since $x$ is primal feasible, $Ax \geq b$ implies $(b_i - \sum_j a_{ij}x_j) \leq 0 \ \ \forall i$.</p>
<p>Similarly, $x_j \geq 0 \ \ \forall j$ and $( \sum_i a_{ij}p_i - c_j) \geq 0 \ \ \forall j$.</p>
<p>So the above expression is a sum of all non-positive terms that adds up to zero. This can only happen if each term is equal to zero.</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="v-poghosyan/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/optimization/applied%20mathematics/proofs/2022/02/07/Optimization-LP-Duality.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Personal blog about Machine Learning, Data Science, Mathematics, Software Engineering, and various other topics. Created by Vahram Poghosyan, © 2021 - Present.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/v-poghosyan" target="_blank" title="v-poghosyan"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/Vahram31680593" target="_blank" title="Vahram31680593"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
